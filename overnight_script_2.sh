# Bkp: lr decay = 0.9
# lr decay = 0.75
# bs=32, epochs=5, lr=0.05(default), cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token prompt_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token maxpool_all --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp_l1 --token answer_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp_l1 --token prompt_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp_l1 --token maxpool_all --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.02, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.02 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.02 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.01, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.01 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.01 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.005, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.005 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.005 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.001, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.001 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.001 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data