# Bkp: lr decay = 0.9
# lr decay = 0.75
# bs=32, epochs=5, lr=0.05(default), cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token prompt_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token maxpool_all --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp_l1 --token answer_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp_l1 --token prompt_last --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp_l1 --token maxpool_all --method individual_linear --bs 32 --epochs 5 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.02, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.02 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.02 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.01, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.01 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.01 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.005, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.005 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.005 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# bs=32, epochs=5, lr=0.001, cls_wgt=True(default), train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.001 --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_train1800 --test_labels_file_name trivia_qa_greedy_responses_labels_train1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 5 --lr 0.001 --use_class_wgt True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

############ Updated test file ###########################################################################
# bs=128, epochs=10 (ES), lr=0.05 (Adam+schr), cls_wgt=False, train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 128 --epochs 10 --lr 0.05 --optimizer Adam_w_lr_sch --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# bs=64, epochs=10 (ES), lr=0.05 (Adam+schr), cls_wgt=False, train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 64 --epochs 10 --lr 0.05 --optimizer Adam_w_lr_sch --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# bs=32, epochs=10 (ES), lr=0.05 (Adam+schr), cls_wgt=False, train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 10 --lr 0.05 --optimizer Adam_w_lr_sch --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# bs=32, epochs=10 (ES), lr=0.005 (Adam+schr), cls_wgt=False, train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 32 --epochs 10 --lr 0.005 --optimizer Adam_w_lr_sch --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data
# bs=16, epochs=10 (ES), lr=0.005 (Adam+schr), cls_wgt=False, train on 1500 (train), test on 1800 (val)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 16 --epochs 10 --lr 0.005 --optimizer Adam_w_lr_sch --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token prompt_last --method individual_linear --bs 128 --epochs 20 --lr 0.05 --optimizer Adam_w_lr_sch --classifier_on_probes True --save_probes True --device 0 --save_path ~/Desktop/honest_llama_data

# (On Ronin)
# python get_activations_and_probe.py llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1500 --num_folds 1 --using_act mlp --token answer_last --method individual_linear --bs 128 --epochs 10 --lr 0.05 --optimizer Adam_w_lr_sch --load_act --classifier_on_probes --save_probes True --device 0 --save_path ~/honest_llama_data