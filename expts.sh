# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method ens_att_pool_hallu_pos --cfr_no_bias True --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True --ind_att_pool_probes_file_name NLSC42_/gemma_2B_/ood_trivia_qa/_city_country_2000_1_layer_att_resFalse_prompt_last_onwards_individual_att_pool_hallu_pos_bs128_epochs50_0.005_Falseba;

# python get_activations.py gemma_2B nq_open --token answer_last --file_name nq_open_greedy_responses_train5000  --device 0 --save_path /home/local/data/ms/honest_llama_data;
# python get_activations.py gemma_2B nq_open --token answer_last --file_name nq_open_greedy_responses_validation1800  --device 0 --save_path /home/local/data/ms/honest_llama_data;
# python get_activations.py gemma_2B nq_open --token prompt_last_onwards --file_name nq_open_greedy_responses_train5000  --device 0 --save_path /home/local/data/ms/honest_llama_data;
# python get_activations.py gemma_2B nq_open --token prompt_last_onwards --file_name nq_open_greedy_responses_validation1800  --device 0 --save_path /home/local/data/ms/honest_llama_data;

# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method individual_att_pool_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method ens_att_pool_hallu_pos --cfr_no_bias True --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --test_num_samples 1 --ind_att_pool_probes_file_name NLSC42_/gemma_2B_/ood_nq_open/_city_country_2000_1_layer_att_resFalse_prompt_last_onwards_individual_att_pool_hallu_pos_bs128_epochs50_0.005_Falseba;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
## OOD
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method individual_att_pool_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method ens_att_pool_hallu_pos --cfr_no_bias True --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True --ind_att_pool_probes_file_name NLSC42_/gemma_2B_/ood_nq_open/_city_country_2000_1_layer_att_resFalse_prompt_last_onwards_individual_att_pool_hallu_pos_bs128_epochs50_0.005_Falseba;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 2000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;