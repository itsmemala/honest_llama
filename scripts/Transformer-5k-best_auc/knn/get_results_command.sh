############## Transformer 1 layer - n ##################################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# ############## Transformer 2 layer - n ########################################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer2_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer2_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

################################### transformer n 1 layer - supcon ####################################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_euclidean5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_euclidean20_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_euclidean50_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_cosine5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_mahalanobis3_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

..

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_euclidean5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_euclidean20_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_euclidean50_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_cosine5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_mahalanobis5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_kmeans_hallu_pos_mahalanobis_wgtd_centers5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

################################### transformer n*aug 1 layer ####################################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_knn_hallu_pos_5_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

################################# transformer n*aug 1 layer : supcon ##########################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_knn_hallu_pos_5_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

# ################################# transformer n*aug 1 layer : supcon+ ##########################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_knn_hallu_pos_5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_knn_hallu_pos_5_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

# ################################# transformer n*aug 1 layer : supcon* ##########################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_wp_knn_hallu_pos_5_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

# ################################# transformer n*aug 1 layer : supcon+* ##########################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_knn_hallu_pos_5_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_knn_hallu_pos_0.3_mahalanobis5_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650