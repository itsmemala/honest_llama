############## Transformer 1 layer - n ##################################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# ############## Transformer 2 layer - n ########################################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

################################# transformer n 1 layer : supcon ##########################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
# (python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650)
# across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0)

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
# (python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650)
# across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0)

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
# (python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650)
# across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,0.5,0.7,1.0,2.0)

################################### transformer n*aug 1 layer ####################################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_hallu_pos_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

################################### transformer n*aug 1 layer: filtered prompts ####################################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp2_3_4_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/nq_open_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp2_3_4_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_/16479_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp2_3_4_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
python analyse_crossdataset_bce_transfmr.py hl_llama_7B gsm8k --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/gsm8k_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp2_3_4_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1

################################# transformer n*aug 1 layer : supcon ##########################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
across sc temp: python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
across sc temp: python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

################################# transformer n 1 layer : supcon+ ##########################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

################################# transformer n*aug 1 layer : supcon+ ##########################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0)

python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
across sc temp: across sc temp: python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

################################# transformer n*aug 1 layer : supcon* ##########################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_wp_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
across sc temp: python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0

python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_wp_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_wp_hallu_pos_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650

################################# transformer n*aug 1 layer : supcon+* ##########################
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
(python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650)
across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0)
(python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall 0.85)
with wgting:
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_1.0_0.3_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42 --sc_temp_list 0.3
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_1.0_0.3_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 101 --sc_temp_list 0.05
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_1.0_0.3_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 2650 --sc_temp_list 0.3
continue ce: 
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42 --sc_temp_list 0.3
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 101 --sc_temp_list 0.05
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 2650 --sc_temp_list 0.3

python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
(python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650)
across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0)
continue ce: 
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42 --sc_temp_list 2.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 101 --sc_temp_list 1.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 2650 --sc_temp_list 2.0

python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
(python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650)
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_all_hallu_pos_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650
across sc temp: (python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0)
continue ce:
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42 --sc_temp_list 2.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 101 --sc_temp_list 0.2
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 2650 --sc_temp_list 1.0

across sc temp: (python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0)
continue ce:
python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42 --sc_temp_list 0.7
python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 101 --sc_temp_list 2.0
python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 2650 --sc_temp_list 0.7

across sc temp: (python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0)
continue ce:
python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42 --sc_temp_list 0.3
python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 101 --sc_temp_list 2.0
python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 2650 --sc_temp_list 2.0

across sc temp: python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
continue ce:
python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42 --sc_temp_list 0.5
python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 101 --sc_temp_list 1.0
python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_cce_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 2650 --sc_temp_list 0.3