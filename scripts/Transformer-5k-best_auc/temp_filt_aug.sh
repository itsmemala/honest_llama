python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2304 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2304 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2304 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

python get_activations_and_probe_transformer.py hl_llama_7B gsm8k --train_file_name gsm8k_sampledplus_responses_train5000 --test_file_name gsm8k_greedy_responses_test1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py alpaca_7B gsm8k --train_file_name gsm8k_sampledplus_responses_train5000 --test_file_name gsm8k_greedy_responses_test1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py vicuna_7B gsm8k --train_file_name gsm8k_sampledplus_responses_train5000 --test_file_name gsm8k_greedy_responses_test1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True  --best_using_auc True --seed_list 42,101,2650 --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True  --best_using_auc True --seed_list 42,101,2650 --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py vicuna_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True  --best_using_auc True --seed_list 42,101,2650 --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python get_activations_and_probe_transformer.py vicuna_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --filt_prompts_catg_list 2,3,4 --no_batch_sampling True --shuffle_batch_prompts True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

########
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/nq_open_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_/16479_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2304_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py hl_llama_7B gsm8k --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/gsm8k_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/alpaca_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_/alpaca_7B_/nq_open_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_/alpaca_7B_/strqa_sampledplus_responses_train_/16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2304_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py alpaca_7B gsm8k --using_act layer --token answer_last --probes_file_name T42_/alpaca_7B_/gsm8k_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0

python analyse_crossdataset_bce_transfmr.py vicuna_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py vicuna_7B nq_open --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/nq_open_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_/16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2304_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0
python analyse_crossdataset_bce_transfmr.py vicuna_7B gsm8k --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/gsm8k_sampledplus_responses_train5000_/55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0