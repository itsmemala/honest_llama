################################# transformer n 1 layer ##########################
# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name trivia_qa_greedy_responses_train5000  --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name nq_open_greedy_responses_validation1800  --device 0 --save_path ~/Desktop/honest_llama_data

python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################### transformer n*aug 1 layer ####################################

# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name trivia_qa_sampledplus_responses_train5000  --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name nq_open_greedy_responses_validation1800  --device 0 --save_path ~/Desktop/honest_llama_data

# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n*aug --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --multi_gpu True --ood_test True
################################# transformer n 2 layer ##########################################

python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n 1 layer : ntx ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supcon_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_ntx-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n 1 layer : supcon ##########################
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n*aug 1 layer : ntx ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supcon_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_ntx-n*aug --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n*aug 1 layer : supcon ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n*aug --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --multi_gpu True --ood_test True
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

################################# transformer n 1 layer : supcon+ ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n*aug 1 layer : supcon+ ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos-n*aug --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --multi_gpu True --ood_test True
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

################################# transformer n*aug 1 layer : supcon* ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_wp_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_wp-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

################################# transformer n*aug 1 layer : supcon+* ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos_wp-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True




################################# transformer n 1 layer ##########################
# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name trivia_qa_greedy_responses_train5000  --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name strqa_baseline_responses_test  --device 0 --save_path ~/Desktop/honest_llama_data

python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################### transformer n*aug 1 layer ####################################

# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name trivia_qa_sampledplus_responses_train5000  --device 0 --save_path ~/Desktop/honest_llama_data
# python get_activations.py hl_llama_7B trivia_qa --token answer_last --file_name strqa_baseline_responses_test  --device 0 --save_path ~/Desktop/honest_llama_data

# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n*aug --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --multi_gpu True --ood_test True
################################# transformer n 2 layer ##########################################

python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n 1 layer : ntx ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supcon_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_ntx-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n 1 layer : supcon ##########################
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n*aug 1 layer : ntx ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supcon_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_ntx-n*aug --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True

################################# transformer n*aug 1 layer : supcon ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n*aug --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --multi_gpu True --ood_test True
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

################################# transformer n 1 layer : supcon+ ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

# ################################# transformer n*aug 1 layer : supcon+ ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos-n*aug --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --multi_gpu True --ood_test True
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

# ################################# transformer n*aug 1 layer : supcon* ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_wp_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_wp-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

# ################################# transformer n*aug 1 layer : supcon+* ##########################
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2_pos_wp-n*aug-b --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --multi_gpu True --ood_test True

python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name nq_open_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name nq_open_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name nq_open_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name nq_open_greedy_responses_validation1800 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name nq_open_greedy_responses_validation1800 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name nq_open_greedy_responses_validation1800 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True

python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name nq_open_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name nq_open_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name strqa_baseline_responses_test --train_labels_file_name nq_open_greedy_responses_labels_train5000 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --ood_test True

python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name trivia_qa_greedy_responses_validation1800 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name nq_open_greedy_responses_validation1800 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name nq_open_greedy_responses_validation1800 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer2-n --tag main-transformer-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name nq_open_greedy_responses_validation1800 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 256 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path ~/Desktop/honest_llama_data --fast_mode True  --plot_name transformer_supconv2-n --tag main-transformer-contrast-5kbestauc-oodtest --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --ood_test True