# python get_activations.py alpaca_7B strqa --token answer_last --file_name strqa_baseline_responses_train  --device 0 --save_path /home/local/data/ms/honest_llama_data
# python get_activations.py alpaca_7B strqa --token answer_last --file_name strqa_baseline_responses_test  --device 0 --save_path /home/local/data/ms/honest_llama_data

python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --plot_name linear-n --tag main-baseline-5kbestauc --use_best_val_t True  --best_using_auc True --seed_list 42,101,2650

python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --plot_name nlinear-n --tag main-baseline-5kbestauc --use_best_val_t True  --best_using_auc True --seed_list 42,101,2650