python get_activations_and_probe_non_linear_supcon_bce.py gemma_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 279;

# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1;

# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1;
# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 1 --skip_to_head 871; #179
# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1;

python get_activations_and_probe_non_linear_supcon_bce.py gemma_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_train True --skip_to_head 279;

# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8

# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10
# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_train True --skip_to_head 871; #179
# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8

# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 10 --skip_train True --skip_to_head 593; #40
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 10 --skip_train True --skip_to_head 529; #8
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 8 --skip_train True --skip_to_head 701; #94

# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 10 --skip_train True --skip_to_head 585; #36 -> 512 + 36*2 + 1
# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 10 --skip_train True --skip_to_head 659; #73
# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 8 --skip_train True --skip_to_head 973; #230

# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 10 --skip_train True --skip_to_head 627; #57
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 10 --skip_train True --skip_to_head 877; #182
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 101,2650 --test_num_samples 8 --skip_train True --skip_to_head 973; #230

### Train on sampled - test on sampled ###
python get_activations_and_probe_non_linear_supcon_bce.py gemma_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --use_val_aug True --skip_to_head ;

# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 75;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 95;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8 --skip_to_head 56;

# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 397;
# # python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 4973*11 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 871; #179
# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8 --skip_to_head 998;

# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 593; #40
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 529; #8
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8 --skip_to_head 701; #94

# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 585; #36 -> 512 + 36*2 + 1
# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 659; #73
# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8 --skip_to_head 973; #230

# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 627; #57
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 10 --skip_to_head 877; #182
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8 --skip_to_head 973; #230

### Train on sampled - test on greedy ###
python get_activations_and_probe_non_linear_supcon_bce.py gemma_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head ;

# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 75;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 95;
# python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 56;

# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 397;
# # python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973*11 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 871; #179
# python get_activations_and_probe_non_linear_supcon_bce.py llama3.1_8B_Instruct strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 998;

# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 593; #40
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 529; #8
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 701; #94

# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 585; #36 -> 512 + 36*2 + 1
# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 659; #73
# python get_activations_and_probe_non_linear_supcon_bce.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 973; #230

# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 627; #57
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 877; #182
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 16479 --num_folds 1 --using_act ah --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1 --skip_to_head 973; #230

## Results ##
# python analyse_crossdataset_bce.py gemma_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_7B_/trivia_qa_greedy_responses_train5000_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma

# python analyse_crossdataset_bce.py gemma_2B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma
# python analyse_crossdataset_bce.py gemma_2B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/nq_open_greedy_responses_train5000_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_baseline_responses_train_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma

# python analyse_crossdataset_bce.py llama3.1_8B_Instruct trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/trivia_qa_greedy_responses_train5000_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma
# python analyse_crossdataset_bce.py llama3.1_8B_Instruct nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/nq_open_greedy_responses_train5000_/4973_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 871
# python analyse_crossdataset_bce.py llama3.1_8B_Instruct strqa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/strqa_baseline_responses_train_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma

# python analyse_crossdataset_bce.py gemma_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_7B_/trivia_qa_greedy_responses_train5000_trivia_qa_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma

# python analyse_crossdataset_bce.py gemma_2B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/trivia_qa_greedy_responses_train5000_trivia_qa_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma
# python analyse_crossdataset_bce.py gemma_2B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/nq_open_greedy_responses_train5000_nq_open_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma

# python analyse_crossdataset_bce.py llama3.1_8B_Instruct trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/trivia_qa_greedy_responses_train5000_trivia_qa_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma
# python analyse_crossdataset_bce.py llama3.1_8B_Instruct nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/nq_open_greedy_responses_train5000_nq_open_sampled_responses_validation1800_/4973_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 871
# python analyse_crossdataset_bce.py llama3.1_8B_Instruct strqa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma

# python analyse_crossdataset_bce.py hl_llama_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_trivia_qa_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 593
# python analyse_crossdataset_bce.py hl_llama_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/nq_open_greedy_responses_train5000_nq_open_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 529
# python analyse_crossdataset_bce.py hl_llama_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 701

# python analyse_crossdataset_bce.py alpaca_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/trivia_qa_greedy_responses_train5000_trivia_qa_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 585
# python analyse_crossdataset_bce.py alpaca_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/nq_open_greedy_responses_train5000_nq_open_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 659
# python analyse_crossdataset_bce.py alpaca_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 973

# python analyse_crossdataset_bce.py vicuna_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/trivia_qa_greedy_responses_train5000_trivia_qa_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 627
# python analyse_crossdataset_bce.py vicuna_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/nq_open_greedy_responses_train5000_nq_open_sampled_responses_validation1800_/5000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 877
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 973

## Results - train on sampled - test on sampled ##
# python analyse_crossdataset_bce.py gemma_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_valaug_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma

# python analyse_crossdataset_bce.py gemma_2B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 75
# python analyse_crossdataset_bce.py gemma_2B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/nq_open_sampledplus_responses_train5000_nq_open_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 95
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 56

# python analyse_crossdataset_bce.py llama3.1_8B_Instruct trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 397
# # python analyse_crossdataset_bce.py llama3.1_8B_Instruct nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/nq_open_sampledplus_responses_train5000_nq_open_sampled_responses_validation1800_/4973_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 871
# python analyse_crossdataset_bce.py llama3.1_8B_Instruct strqa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 998

# python analyse_crossdataset_bce.py hl_llama_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 593
# python analyse_crossdataset_bce.py hl_llama_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/nq_open_sampledplus_responses_train5000_nq_open_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 529
# python analyse_crossdataset_bce.py hl_llama_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 701

# python analyse_crossdataset_bce.py alpaca_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 585
# python analyse_crossdataset_bce.py alpaca_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/nq_open_sampledplus_responses_train5000_nq_open_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 659
# python analyse_crossdataset_bce.py alpaca_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 973

# python analyse_crossdataset_bce.py vicuna_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 627
# python analyse_crossdataset_bce.py vicuna_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/nq_open_sampledplus_responses_train5000_nq_open_sampled_responses_validation1800_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 877
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --layer_strat ma --skip_to_model 973

## Results - train on sampled - test on greedy ##
# python analyse_crossdataset_bce.py gemma_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 75

# python analyse_crossdataset_bce.py gemma_2B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 75
# python analyse_crossdataset_bce.py gemma_2B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/nq_open_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 95
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_sampledplus_responses_train_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 56

# python analyse_crossdataset_bce.py llama3.1_8B_Instruct trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/trivia_qa_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 397
# # python analyse_crossdataset_bce.py llama3.1_8B_Instruct nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/nq_open_sampledplus_responses_train5000_/4973_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 871
# python analyse_crossdataset_bce.py llama3.1_8B_Instruct strqa --using_act ah --token answer_last --probes_file_name NLSC42_/llama3.1_8B_Instruct_/strqa_sampledplus_responses_train_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 998

# python analyse_crossdataset_bce.py hl_llama_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 593
# python analyse_crossdataset_bce.py hl_llama_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/nq_open_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 529
# python analyse_crossdataset_bce.py hl_llama_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/hl_llama_7B_/strqa_sampledplus_responses_train_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 701

# python analyse_crossdataset_bce.py alpaca_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 585
# python analyse_crossdataset_bce.py alpaca_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/nq_open_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 659
# python analyse_crossdataset_bce.py alpaca_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/alpaca_7B_/strqa_sampledplus_responses_train_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 973

# python analyse_crossdataset_bce.py vicuna_7B trivia_qa --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/trivia_qa_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 627
# python analyse_crossdataset_bce.py vicuna_7B nq_open --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/nq_open_sampledplus_responses_train5000_/55000_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 877
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act ah --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_sampledplus_responses_train_/16479_1_ahFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --layer_strat ma --skip_to_model 973
