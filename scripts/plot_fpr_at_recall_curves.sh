# python analyse_crossdataset_bce.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name NLSC42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name NLSC42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name NLSC42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name NLSC42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name NLSC42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_individual_linear_kmeans_hallu_pos_mahalanobis_centers1pca0.9_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --probes_file_name_concat ba_bestusinglast

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_kmeans_hallu_pos_mahalanobis_centers1_bs128_epochs50_ --probes_file_name_concat ba_bestusinglast --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_batchnorm_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_0.5_0.5_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.05_mahalanobis_centers1pca0.9_bs352_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.05_mahalanobis_centers1pca0.9_bs352_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.05_mahalanobis_centers1pca0.9_bs352_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.05_mahalanobis_centers1pca0.9_bs352_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.05_mahalanobis_centers1_batchnorm_bs288_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.05_0.5_0.5_mahalanobis_centers1pca0.9_bs352_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

#################### Ablations ###########################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer_supconv2_pos_kmeans_hallu_pos_0.05_mahalanobis_centers1_bs256_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_kmeans_hallu_pos_mahalanobis_centers1_bs128_epochs50_ --probes_file_name_concat ba_bestusinglast --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_kmeans_hallu_pos_0.5_mahalanobis_centers1_bs256_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.5_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_bs352_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.05_batchnorm_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_sampledplus_responses_train5000_55000_1_layerFalse_answer_last_transformer_supconv2_pos_kmeans_hallu_pos_0.05_mahalanobis_centers1pca0.9_bs352_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

##################### TRnsfrmr 2 layer
python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py hl_llama_7B nq_open --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py alpaca_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_trivia_qa_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650
python analyse_crossdataset_bce_transfmr.py alpaca_7B nq_open --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_nq_open_greedy_responses_train5000_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650


##########################
######## STR #############
# python analyse_crossdataset_bce.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.05_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.3_mahalanobis_centers1pca0.9_bs288_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_kmeans_hallu_pos_0.3_mahalanobis_centers1pca0.9_bs288_epochs500_ --probes_file_name_concat ba_bestusinglast --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1

####################### Abltaions ################
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.05_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs256_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_sampledplus_responses_train_16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1

###################### TRnsfrmr 2 layer
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_hl_llama_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1
# python analyse_crossdataset_bce_transfmr.py alpaca_7B strqa --using_act layer --token answer_last --probes_file_name T42_alpaca_7B_strqa_baseline_responses_train_1832_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path ~/Desktop/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1