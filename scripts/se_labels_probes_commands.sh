# python get_uncertainty_scores.py hl_llama_7B trivia_qa --file_name sampledplus_responses_train5000 --save_path /home/local/data/ms/honest_llama_data --num_samples 10
# python get_uncertainty_scores.py hl_llama_7B nq_open --file_name sampledplus_responses_train5000 --save_path /home/local/data/ms/honest_llama_data --num_samples 10  # We only need sampled responses (no greedy responses) for SE
# python get_uncertainty_scores.py hl_llama_7B city_country --file_name sampledplus_responses_train1000 --save_path /home/local/data/ms/honest_llama_data --num_samples 10  # We only need sampled responses (no greedy responses) for SE
# python get_uncertainty_scores.py hl_llama_7B player_date_birth --file_name sampledplus_responses_train1000 --save_path /home/local/data/ms/honest_llama_data --num_samples 10
python get_uncertainty_scores.py hl_llama_7B movie_cast --file_name sampledplus_responses_train1000 --save_path /home/local/data/ms/honest_llama_data --num_samples 10


python get_semantic_entropy_fast.py hl_llama_7B trivia_qa --file_name sampledplus_responses_train5000  --save_path /home/local/data/ms/honest_llama_data --num_samples 10 # We only need sampled responses (no greedy responses) for SE
python get_semantic_entropy_fast.py hl_llama_7B nq_open --file_name sampledplus_responses_train5000  --save_path /home/local/data/ms/honest_llama_data --num_samples 10 # We only need sampled responses (no greedy responses) for SE
# python get_semantic_entropy.py hl_llama_7B city_country --file_name sampledplus_responses_train1000  --save_path /home/local/data/ms/honest_llama_data --num_samples 10 # We only need sampled responses (no greedy responses) for SE
# python get_semantic_entropy.py hl_llama_7B player_date_birth --file_name sampledplus_responses_train1000  --save_path /home/local/data/ms/honest_llama_data --num_samples 10 # We only need sampled responses (no greedy responses) for SE
python get_semantic_entropy_fast.py hl_llama_7B movie_cast --file_name sampledplus_responses_train1000  --save_path /home/local/data/ms/honest_llama_data --num_samples 10 # We only need sampled responses (no greedy responses) for SE
# python get_semantic_entropy.py hl_llama_7B strqa --file_name sampledplus_responses_train  --save_path /home/local/data/ms/honest_llama_data --num_samples 8 # We only need sampled responses (no greedy responses) for SE


# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --train_labels_file_name strqa_sampledplus_responses_train_se_labels --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 1
# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B strqa --train_file_name strqa_baseline_responses_train --train_labels_file_name strqa_sampledplus_responses_train_se_labels --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8 --skip_train