################################# cross-layer ablations ##########################################
## TRAIN ON GREEDY TEST ON GREEDY
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1
# Layers Maxpool -> Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer_maxpool --token answer_last --method linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1
# # Layers Project + Concat -> Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True;
# ## Layers Maxpool -> Non-Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer_maxpool --token answer_last --method non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
# ## Layers Project + Concat -> Non-Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True;
## TRAIN ON GREEDY TEST ON GREEDY - OOD
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
# Layers Maxpool -> Linear
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer_maxpool --token answer_last --method linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
# Layers Project + Concat -> Linear
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --ood_test True --skip_train True;
python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name city_country_greedy_responses_test1581 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name city_country_greedy_responses_labels_test1581 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True --ood_test True --skip_train True;
## TRAIN ON SAMPLED TEST ON SAMPLED
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True
## Layers Maxpool -> Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer_maxpool --token answer_last --method linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True
## Layers Project + Concat -> Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 256;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 512;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 4096 --no_act_proj True;
# ## Layers Maxpool -> Non-Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer_maxpool --token answer_last --method non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True;
# ## Layers Project + Concat -> Non-Linear
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 256;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 512;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py hl_llama_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 4096 --no_act_proj True;

# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True
## Layers Maxpool -> Linear
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer_maxpool --token answer_last --method linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True
# ## Layers Project + Concat -> Linear
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 256;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 512;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 4096 --no_act_proj True;
## Layers Maxpool -> Non-Linear
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer_maxpool --token answer_last --method non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True;
# ## Layers Project + Concat -> Non-Linear
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 256;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 512;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py hl_llama_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --shuffle_batch_prompts True --tfr_d_model 4096 --no_act_proj True;

# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True
# Layers Maxpool -> Linear
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer_maxpool --token answer_last --method linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True
# # Layers Project + Concat -> Linear
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 2048 --no_act_proj True;
## Layers Maxpool -> Non-Linear
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer_maxpool --token answer_last --method non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True;
# ## Layers Project + Concat -> Non-Linear
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method project_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 10 --shuffle_batch_prompts True --tfr_d_model 2048 --no_act_proj True;

#################################### d_model, n_enc ablations ###############################

# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --no_act_proj True;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --no_act_proj True;

# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --no_act_proj True;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --no_act_proj True;

# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --no_act_proj True;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048 --no_act_proj True;

# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048;
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True;

# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct nq_open --train_file_name nq_open_greedy_responses_train5000 --test_file_name nq_open_greedy_responses_validation1800 --train_labels_file_name nq_open_greedy_responses_labels_train5000 --test_labels_file_name nq_open_greedy_responses_labels_validation1800 --len_dataset 4973 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True

# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 256
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 512
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 1024
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 2048
# python get_activations_and_probe_transformer.py llama3.1_8B_Instruct strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_baseline_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 1 --tfr_d_model 4096 --no_act_proj True


##################### Get Results ###################
# cross-layer ablations ##
## TRAIN ON GREEDY TEST ON GREEDY
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --show_val_res True # Test: 81.8 (0.5), Val: 84.0 (0.1)
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 --show_val_res True # Test: 80.6 (1.8), Val: 82.0 (1.0)
# ## Layers Maxpool -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layer_maxpoolFalse_answer_last_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# ## Layers Project + Concat -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel256_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel512_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel1024_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel2048_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel4096noactproj_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# ## Layers Maxpool -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layer_maxpoolFalse_answer_last_non_linear_4_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# ## Layers Project + Concat -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_dmodel256_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_dmodel512_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_dmodel1024_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_dmodel2048_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_dmodel4096noactproj_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
## TRAIN ON GREEDY TEST ON GREEDY - OOD
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True # Test: 54.4 (1.3)
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True # Test: 
# ## Layers Maxpool -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layer_maxpoolFalse_answer_last_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# ## Layers Project + Concat -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_project_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel256_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel512_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel1024_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel2048_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/ood_trivia_qa/_city_country_5000_1_layerFalse_answer_last_project_linear_hallu_pos_dmodel4096noactproj_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 1 #--show_val_res True
## TRAIN ON SAMPLED TEST ON SAMPLED
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True # 91.4 (0.3), 88.7 (1.1)
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True # 91.4 (0.4), 88.9 (1.1)
# ## Layers Maxpool -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layer_maxpoolFalse_answer_last_linear_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# ## Layers Project + Concat -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel256_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel512_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel1024_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel2048_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel4096noactproj_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# ## Layers Maxpool -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layer_maxpoolFalse_answer_last_non_linear_4_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# ## Layers Project + Concat -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel256_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel512_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel1024_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel2048_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel4096noactproj_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True

# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True # 86.5 (0.1), 86.9 (0.4)
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True # 86.4 (0.1), 87.7 (0.8)
# ## Layers Maxpool -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layer_maxpoolFalse_answer_last_linear_hallu_pos_shufflebp_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# ## Layers Project + Concat -> Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel256_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel512_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel1024_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel2048_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel4096noactproj_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# ## Layers Maxpool -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layer_maxpoolFalse_answer_last_non_linear_4_hallu_pos_shufflebp_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# ## Layers Project + Concat -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel256_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel512_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel1024_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel2048_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py hl_llama_7B strqa --using_act layer --token answer_last --probes_file_name T42_/hl_llama_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel4096noactproj_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --show_val_res True

# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True # 
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True # 
# ## Layers Maxpool -> Linear
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layer_maxpoolFalse_answer_last_linear_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# ## Layers Project + Concat -> Linear
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel256_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel512_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel1024_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_linear_hallu_pos_shufflebp_dmodel2048noactproj_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# # Layers Maxpool -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layer_maxpoolFalse_answer_last_non_linear_4_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# # Layers Project + Concat -> Non-Linear
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel256_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel512_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel1024_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_sampledplus_responses_train5000_trivia_qa_sampled_responses_validation1800_/55000_1_layerFalse_answer_last_project_non_linear_4_hallu_pos_shufflebp_dmodel2048noactproj_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 10 --show_val_res True

## d_model, n_enc ablations ##
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer_hallu_pos_dmodel256_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer_hallu_pos_dmodel512_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer_hallu_pos_dmodel1024_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer_hallu_pos_dmodel2048noactproj_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer2_hallu_pos_dmodel256_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer2_hallu_pos_dmodel512_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer2_hallu_pos_dmodel1024_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True
# python analyse_crossdataset_bce_transfmr.py gemma_2B trivia_qa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/trivia_qa_greedy_responses_train5000_/5000_1_layerFalse_answer_last_transformer2_hallu_pos_dmodel2048noactproj_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --show_val_res True