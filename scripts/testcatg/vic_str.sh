# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --skip_train True --test_num_samples 8 --last_only True
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --skip_train True --test_num_samples 8 --last_only True

################# n*aug #############################
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --skip_train True --test_num_samples 8 --last_only True
# python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --skip_train True --test_num_samples 8 --last_only True

python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 288 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --no_batch_sampling True --test_num_samples 8 --last_only True
python get_activations_and_probe_non_linear_supcon_bce.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 288 --epochs 50 --lr_list 0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --no_batch_sampling True --test_num_samples 8 --last_only True

################ CLAP #########################
python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --skip_train True --test_num_samples 8
python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --skip_train True --test_num_samples 8
python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8

# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --skip_train True --test_num_samples 8 --filt_prompts_catg_list 2,3,4
# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --skip_train True --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True
# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --skip_train True --test_num_samples 8 --filt_prompts_catg_list 4 --shuffle_batch_prompts True

# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 288 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 8
# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 288 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 8
# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 288 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 8

# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True
# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True
# python get_activations_and_probe_transformer.py vicuna_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True

######### Get results ##########
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_layerFalse_answer_last_individual_non_linear_4_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_non_linear_4_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_linear_hallu_pos_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_non_linear_4_hallu_pos_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_hallu_pos_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 0,1,2,3,4
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_hallu_pos2_3_4_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp2_3_4_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_hallu_pos_shufflebp4_bs288_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_supconv2_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# # python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_supconv2_pos_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.05,0.1,0.2,0.3,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# # python analyse_crossdataset_bce_transfmr.py vicuna_7B strqa --using_act layer --token answer_last --probes_file_name T42_/vicuna_7B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer_supconv2_pos_wp_hallu_pos_0.1_bs288_epochs500_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
#
#
#
