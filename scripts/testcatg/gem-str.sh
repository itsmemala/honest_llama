python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8

################# n*aug #############################
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --test_num_samples 8

python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_linear_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --no_batch_sampling True --test_num_samples 8
python get_activations_and_probe_non_linear_supcon_bce.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method individual_non_linear_4_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005,0.05,0.5 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True --use_best_val_t True --best_using_auc True --seed_list 42,101,2650 --no_batch_sampling True --test_num_samples 8

################ CLAP #########################
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_baseline_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 1832 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True --seed_list 42,101,2650 --best_using_auc True --test_num_samples 8
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 8
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8  --shuffle_batch_prompts True

python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --test_num_samples 8 --filt_prompts_catg_list 2,3,4
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8 --filt_prompts_catg_list 4 --shuffle_batch_prompts True

python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --test_num_samples 8 --shuffle_batch_prompts True
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --test_num_samples 8 --shuffle_batch_prompts True
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --test_num_samples 8 --shuffle_batch_prompts True

python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True
python get_activations_and_probe_transformer.py gemma_2B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 2816 --epochs 250 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --test_num_samples 8 --filt_prompts_catg_list 2,3,4 --shuffle_batch_prompts True

######### Get results ##########
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --filt_testprompts_catg 0 --test_num_samples 8
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_layerFalse_answer_last_individual_non_linear_4_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --filt_testprompts_catg 0 --test_num_samples 8
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_linear_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_non_linear_4_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_linear_hallu_pos_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name NLSC42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_individual_non_linear_4_hallu_pos_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005,0.05,0.5 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_baseline_responses_train_strqa_sampled_responses_test_/1832_1_layerFalse_answer_last_transformer_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_hallu_pos_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_hallu_pos2_3_4_bs128_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp2_3_4_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_hallu_pos_shufflebp4_bs352_epochs50_ --probes_file_name_concat ba --lr_list 0.00005,0.0005,0.005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_supconv2_hallu_pos_0.1_shufflebp_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_supconv2_pos_hallu_pos_0.1_shufflebp_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_supconv2_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_supconv2_pos_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
# python analyse_crossdataset_bce_transfmr.py gemma_2B strqa --using_act layer --token answer_last --probes_file_name T42_/gemma_2B_/strqa_sampledplus_responses_train_strqa_sampled_responses_test_/16479_1_layerFalse_answer_last_transformer2_supconv2_pos_wp_hallu_pos_0.1_shufflebp2_3_4_bs2816_epochs250_ --probes_file_name_concat ba --lr_list 0.000005,0.00005,0.0005 --best_threshold True --save_path /home/local/data/ms/honest_llama_data --seed_list 42,101,2650 --sc_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --fpr_at_recall -1 --test_num_samples 8 --filt_testprompts_catg 2
