python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --skip_train True --test_num_samples 10  --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 10  --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 10  --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
python get_activations_and_probe_transformer.py alpaca_7B trivia_qa --train_file_name trivia_qa_sampledplus_responses_train5000 --test_file_name trivia_qa_sampled_responses_validation1800 --train_labels_file_name trivia_qa_sampledplus_responses_labels_train5000 --test_labels_file_name trivia_qa_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer2_supconv2_pos_wp_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 10  --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
printf ('\n\nTQA FINISHED\n\n')

python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 352 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --skip_train True --test_num_samples 10  --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 10 --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 10 --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
python get_activations_and_probe_transformer.py alpaca_7B nq_open --train_file_name nq_open_sampledplus_responses_train5000 --test_file_name nq_open_sampled_responses_validation1800 --train_labels_file_name nq_open_sampledplus_responses_labels_train5000 --test_labels_file_name nq_open_sampled_responses_labels_validation1800 --len_dataset 55000 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 352 --epochs 500 --lr_list 0.000005,0.00005,0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.1,0.3,0.5,0.7,1.0,2.0 --skip_train True --test_num_samples 10 --wp_dist True --wpdist_metric cosine --test_bs 10 --skip_train_acts True
printf ('\n\nNQ FINISHED\n\n')

python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_hallu_pos --bs 288 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42,101,2650 --best_using_auc True --no_batch_sampling True --test_num_samples 8  --wp_dist True --wpdist_metric cosine --test_bs 10
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_hallu_pos --bs 2304 --epochs 250 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 2.0 --test_num_samples 8  --wp_dist True --wpdist_metric cosine --test_bs 10
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_hallu_pos --bs 2304 --epochs 250 --lr_list 0.0005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 0.5 --test_num_samples 8  --wp_dist True --wpdist_metric cosine --test_bs 10
python get_activations_and_probe_transformer.py alpaca_7B strqa --train_file_name strqa_sampledplus_responses_train --test_file_name strqa_sampled_responses_test --len_dataset 16479 --num_folds 1 --using_act layer --token answer_last --method transformer_supconv2_pos_wp_hallu_pos --bs 2304 --epochs 250 --lr_list 0.00005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 101,2650 --best_using_auc True --no_batch_sampling True --supcon_temp_list 1.0 --test_num_samples 8  --wp_dist True --wpdist_metric cosine --test_bs 10
