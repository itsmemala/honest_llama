python get_activations.py hl_llama_7B trivia_qa --token prompt_last_onwards --file_name trivia_qa_greedy_responses_train5000  --device 0 --save_path /home/local/data/ms/honest_llama_data;
python get_activations.py hl_llama_7B trivia_qa --token prompt_last_onwards --file_name trivia_qa_greedy_responses_validation1800  --device 0 --save_path /home/local/data/ms/honest_llama_data;
python get_activations.py hl_llama_7B trivia_qa --token prompt_last_onwards --file_name trivia_qa_sampledplus_responses_train5000  --device 0 --save_path /home/local/data/ms/honest_llama_data --num_samples 11;
python get_activations.py hl_llama_7B trivia_qa --token prompt_last_onwards --file_name trivia_qa_sampled_responses_validation1800  --device 0 --save_path /home/local/data/ms/honest_llama_data --num_samples 10;

# python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 1000 --num_folds 1 --using_act layer --token answer_last --method individual_att_pool_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --test_num_samples 1
python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act layer_att_res --token prompt_last_onwards --method individual_att_pool_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --test_num_samples 1
python get_activations_and_probe_non_linear_supcon_bce.py hl_llama_7B trivia_qa --train_file_name trivia_qa_greedy_responses_train5000 --test_file_name trivia_qa_greedy_responses_validation1800 --train_labels_file_name trivia_qa_greedy_responses_labels_train5000 --test_labels_file_name trivia_qa_greedy_responses_labels_validation1800 --len_dataset 5000 --num_folds 1 --using_act att_pool_emb --token prompt_last_onwards --method ens_att_pool_hallu_pos --bs 128 --epochs 50 --lr_list 0.00005,0.0005,0.005 --save_probes True --save_path /home/local/data/ms/honest_llama_data --fast_mode True  --use_best_val_t True  --seed_list 42 --best_using_auc True --test_num_samples 1

# num layers
# Save emb