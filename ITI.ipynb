{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQLBR5DLie_"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq4kYbFQZL_R",
        "outputId": "90aaed36-b2c5-4a0c-d4d4-46c87ef84aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'honest_llama'...\n",
            "remote: Enumerating objects: 324, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 324 (delta 168), reused 140 (delta 84), pack-reused 85\u001b[K\n",
            "Receiving objects: 100% (324/324), 1.67 MiB | 12.48 MiB/s, done.\n",
            "Resolving deltas: 100% (211/211), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/itsmemala/honest_llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCUAebThbu7d",
        "outputId": "f5eb4480-a728-45cb-dfc2-5e32bad9b77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/honest_llama\n"
          ]
        }
      ],
      "source": [
        "%cd /content/honest_llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwVSjIosLYsQ",
        "outputId": "4b447dbf-66b6-4308-c90e-66e0e6bbed34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:07\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rlHnS6ytgns",
        "outputId": "2bb60d23-a24b-4187-cf76-c2f7a4eda2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/honest_llama\n"
          ]
        }
      ],
      "source": [
        "%cd /content/honest_llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ_oSXi8dhPp",
        "outputId": "ee77b4d1-6994-4c5d-a738-91802bb90f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2024.2.2   |       hbcca054_0         152 KB  conda-forge\n",
            "    certifi-2024.2.2           |     pyhd8ed1ab_0         157 KB  conda-forge\n",
            "    openssl-3.2.1              |       hd590300_1         2.7 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         3.0 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                     2023.11.17-hbcca054_0 --> 2024.2.2-hbcca054_0 \n",
            "  certifi                           2023.11.17-pyhd8ed1ab_0 --> 2024.2.2-pyhd8ed1ab_0 \n",
            "  openssl                                  3.2.0-hd590300_1 --> 3.2.1-hd590300_1 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.10/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "modified      /root/.bashrc\n",
            "\n",
            "==> For changes to take effect, close and re-open your current shell. <==\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... failed\n",
            "\n",
            "PackagesNotFoundError: The following packages are not available from current channels:\n",
            "\n",
            "  - _license\n",
            "\n",
            "Current channels:\n",
            "\n",
            "  - https://conda.anaconda.org/conda-forge\n",
            "\n",
            "To search for alternate channels that may provide the conda package you're\n",
            "looking for, navigate to\n",
            "\n",
            "    https://anaconda.org\n",
            "\n",
            "and use the search bar at the top of the page.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda update conda -y -q\n",
        "!source /usr/local/etc/profile.d/conda.sh\n",
        "!conda init\n",
        "!conda install -n root _license -y -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIShh0ICfMNg",
        "outputId": "48a6857f-b012-4441-8066-9428bbd02ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "libnpp-dev-11.8.0.86 | 144.5 MB  | :  92% 0.915399952074425/1 [00:29<00:00,  5.30s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  83% 0.828818047756609/1 [00:29<00:00,  5.00s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  96% 0.9640619843336421/1 [00:29<00:01, 47.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-dev-11.8.0.86 | 144.5 MB  | :  93% 0.9343288179155008/1 [00:29<00:00,  5.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  85% 0.8512481071348408/1 [00:29<00:00,  4.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  97% 0.96619174124296/1 [00:29<00:01, 47.36s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-dev-11.8.0.86 | 144.5 MB  | :  95% 0.9534740136519031/1 [00:29<00:00,  5.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  87% 0.8720369426561286/1 [00:29<00:00,  4.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  97% 0.9683454280051917/1 [00:29<00:01, 47.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-dev-11.8.0.86 | 144.5 MB  | :  97% 0.973917188760265/1 [00:29<00:00,  5.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  89% 0.8927163632536202/1 [00:29<00:00,  4.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  97% 0.9705948341790781/1 [00:29<00:01, 46.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-dev-11.8.0.86 | 144.5 MB  | : 100% 0.9954420133452597/1 [00:29<00:00,  5.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  91% 0.9137240286225007/1 [00:29<00:00,  4.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  97% 0.9731074687350151/1 [00:29<00:01, 44.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  94% 0.9358258432293436/1 [00:29<00:00,  4.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  98% 0.9755961734380384/1 [00:29<00:01, 42.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  96% 0.9593500518455377/1 [00:29<00:00,  4.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  98% 0.9782284572585438/1 [00:29<00:00, 41.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  98% 0.9832025052331207/1 [00:29<00:00,  4.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  98% 0.9806812671821965/1 [00:29<00:00, 41.23s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  98% 0.9833255159291587/1 [00:29<00:00, 40.16s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  99% 0.9858261855586389/1 [00:30<00:00, 44.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  99% 0.9885302589378854/1 [00:30<00:00, 41.99s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :   0% 0.00013664122410520993/1 [00:30<61:27:52, 221303.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  99% 0.9919402629780855/1 [00:30<00:00, 37.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | :  99% 0.9946563012837888/1 [00:30<00:00, 38.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  62% 0.6246989641131047/1 [00:30<00:01,  3.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | : 100% 0.9972646552513805/1 [00:30<00:00, 39.28s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  65% 0.6541700306417656/1 [00:30<00:01,  3.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | : 100% 0.9998371144396017/1 [00:30<00:00, 40.13s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  68% 0.6807925925988833/1 [00:30<00:01,  3.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  11% 0.11231908621448257/1 [00:30<01:30, 102.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  71% 0.7108114484682256/1 [00:30<00:01,  3.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  15% 0.14907557549878406/1 [00:30<00:51, 60.84s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  74% 0.7435692510409753/1 [00:30<00:00,  3.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  18% 0.18159618683582401/1 [00:30<00:33, 40.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  77% 0.7726020860970911/1 [00:30<00:00,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  22% 0.2160297753103369/1 [00:30<00:21, 27.87s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  81% 0.8074414881644302/1 [00:31<00:00,  3.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  26% 0.2581152723347416/1 [00:31<00:13, 18.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  30% 0.29514504406725345/1 [00:31<00:09, 13.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  84% 0.8380081333744541/1 [00:31<00:00,  3.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  33% 0.3313549684551341/1 [00:31<00:06, 10.08s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  87% 0.8681365471119328/1 [00:31<00:00,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  37% 0.3672916103948043/1 [00:31<00:04,  7.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  90% 0.8974980557724576/1 [00:31<00:00,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  40% 0.4032282523344745/1 [00:31<00:03,  6.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  93% 0.926750006564846/1 [00:31<00:00,  3.47s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  44% 0.4386183293777239/1 [00:31<00:02,  5.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  96% 0.9585217883243691/1 [00:31<00:00,  3.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  47% 0.47482825376560456/1 [00:31<00:02,  4.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | :  99% 0.9883215284574389/1 [00:31<00:00,  3.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  51% 0.5147274912043258/1 [00:31<00:01,  3.89s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  56% 0.5550366523153628/1 [00:31<00:01,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  60% 0.6012213860629237/1 [00:31<00:01,  3.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  64% 0.6424870357426972/1 [00:32<00:01,  2.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  69% 0.6867587923527851/1 [00:32<00:00,  2.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  73% 0.7300740603941367/1 [00:32<00:00,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  77% 0.7748923819006456/1 [00:32<00:00,  2.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  82% 0.8202572683035753/1 [00:32<00:00,  2.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  86% 0.8639824600172424/1 [00:32<00:00,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  91% 0.9119435296781712/1 [00:32<00:00,  2.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :   0% 0.0001375153730125896/1 [00:32<66:07:54, 238106.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | :  97% 0.9745252103183573/1 [00:32<00:00,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :   4% 0.03657908922134883/1 [00:32<10:07, 630.05s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  10% 0.09667330722785047/1 [00:32<02:50, 189.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.0001619872369599508/1 [00:32<56:32:10, 203563.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  15% 0.14700393375045825/1 [00:33<01:28, 103.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   4% 0.04438450292702652/1 [00:33<08:19, 522.89s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   9% 0.08941695480189284/1 [00:33<03:15, 214.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  20% 0.19719704490005346/1 [00:33<00:51, 64.30s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  13% 0.13412543220283926/1 [00:33<01:42, 117.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  24% 0.2388642029228681/1 [00:33<00:34, 44.72s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  18% 0.1760801265754665/1 [00:33<01:01, 74.06s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  28% 0.2783311149774813/1 [00:33<00:23, 32.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  22% 0.21738687200025397/1 [00:33<00:38, 49.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  32% 0.3155977810638931/1 [00:33<00:16, 23.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  26% 0.2572357322924019/1 [00:33<00:25, 34.14s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  35% 0.35038917043607826/1 [00:33<00:11, 18.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  30% 0.29611266916279005/1 [00:33<00:17, 24.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  38% 0.38476801368922564/1 [00:33<00:08, 13.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  33% 0.33498960603317823/1 [00:33<00:11, 17.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  42% 0.42052201067249895/1 [00:33<00:06, 10.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  38% 0.3771062876427655/1 [00:33<00:07, 12.73s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  46% 0.45503836929865893/1 [00:33<00:04,  8.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  42% 0.42068085438499225/1 [00:34<00:05,  9.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  49% 0.4899672740438567/1 [00:34<00:03,  6.76s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  46% 0.46214958704673964/1 [00:34<00:03,  7.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  53% 0.5262713325191803/1 [00:34<00:02,  5.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  50% 0.5031323579976071/1 [00:34<00:02,  5.81s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  56% 0.5628504217405291/1 [00:34<00:02,  4.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  54% 0.5446010906593546/1 [00:34<00:02,  4.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  60% 0.5983293879777772/1 [00:34<00:01,  4.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  59% 0.5855838616102221/1 [00:34<00:01,  4.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  63% 0.6344959310800883/1 [00:34<00:01,  3.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  63% 0.6265666325610897/1 [00:34<00:01,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  67% 0.6713500510474624/1 [00:34<00:01,  3.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  67% 0.6701411993033165/1 [00:34<00:01,  3.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  71% 0.7080666556418238/1 [00:34<00:00,  3.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  72% 0.7153356384151427/1 [00:34<00:00,  2.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  74% 0.7442331987441348/1 [00:34<00:00,  3.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  76% 0.7579382817356098/1 [00:34<00:00,  2.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  78% 0.7825999878146473/1 [00:34<00:00,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  80% 0.8026467591365563/1 [00:34<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  82% 0.8193165924090087/1 [00:35<00:00,  2.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :   0% 0.00023559561249761676/1 [00:35<41:16:10, 148605.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  85% 0.8458973514048631/1 [00:35<00:00,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :   4% 0.0449987619870448/1 [00:35<08:43, 547.71s/it]          \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  86% 0.8560331970033701/1 [00:35<00:00,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  89% 0.88898595643621/1 [00:35<00:00,  2.71s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :   9% 0.09494503183653956/1 [00:35<03:12, 212.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  89% 0.8894494326454294/1 [00:35<00:00,  3.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  93% 0.928672829491398/1 [00:35<00:00,  2.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  14% 0.14277094117355577/1 [00:35<01:40, 116.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  92% 0.9213529991843502/1 [00:35<00:00,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  97% 0.9662538684661065/1 [00:35<00:00,  2.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  19% 0.18941887244808386/1 [00:35<00:58, 72.20s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  95% 0.9518814119931451/1 [00:35<00:00,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  24% 0.24077871597256434/1 [00:35<00:34, 45.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | :  98% 0.9848851015161666/1 [00:35<00:00,  3.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  30% 0.3008555971594566/1 [00:35<00:19, 28.52s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  39% 0.38590561327109624/1 [00:35<00:10, 16.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :   0% 0.00029082654202590864/1 [00:35<34:09:36, 123012.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  50% 0.4971067423699714/1 [00:35<00:04,  9.47s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :   8% 0.07590572746876215/1 [00:35<05:06, 331.62s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  59% 0.5854550970565776/1 [00:35<00:02,  6.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  15% 0.1515206283954984/1 [00:36<01:57, 137.91s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  67% 0.6667355833682554/1 [00:36<00:01,  5.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  23% 0.229171315116416/1 [00:36<00:57, 74.66s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  75% 0.7463669003924499/1 [00:36<00:01,  3.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  31% 0.30856696108948906/1 [00:36<00:31, 45.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  82% 0.8215219007791896/1 [00:36<00:00,  3.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  39% 0.38621764781040663/1 [00:36<00:17, 29.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  89% 0.8933785625909627/1 [00:36<00:00,  2.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  46% 0.4621233752791688/1 [00:36<00:10, 19.92s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  96% 0.9624080770527644/1 [00:36<00:00,  2.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  54% 0.5371566231218532/1 [00:36<00:06, 13.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  65% 0.649415668343854/1 [00:36<00:03,  8.64s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  78% 0.7811600918815905/1 [00:36<00:01,  5.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  89% 0.8937099636456172/1 [00:36<00:00,  3.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | : 100% 0.9981166922329184/1 [00:36<00:00,  3.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :   0% 0.00029378014500947795/1 [00:37<35:10:51, 126688.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  13% 0.12573790206405655/1 [00:37<03:01, 208.14s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  25% 0.25118202398310363/1 [00:37<01:04, 86.26s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :   0% 0.00032070288426088545/1 [00:37<32:27:15, 116872.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :   0% 0.0003699050790694684/1 [00:37<28:09:26, 101404.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  43% 0.4295065720038567/1 [00:37<00:22, 39.63s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :   7% 0.07344096049574277/1 [00:37<05:32, 359.09s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :   8% 0.07989949707900516/1 [00:37<05:03, 330.34s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  15% 0.14656121810722464/1 [00:37<02:07, 149.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  16% 0.1590591839998714/1 [00:37<01:55, 137.43s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  58% 0.5781593253786526/1 [00:37<00:10, 24.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  21% 0.21294671514922794/1 [00:37<01:07, 85.37s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  24% 0.2363693455253903/1 [00:37<00:58, 76.35s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  27% 0.27484237181157883/1 [00:37<00:39, 54.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  31% 0.30554159531138086/1 [00:37<00:34, 49.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  69% 0.6889144400472257/1 [00:38<00:05, 18.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  34% 0.33641732558966886/1 [00:38<00:24, 36.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  37% 0.3721245095438852/1 [00:38<00:20, 33.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  39% 0.39382314187236733/1 [00:38<00:15, 25.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  44% 0.4405569491717368/1 [00:38<00:12, 22.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  78% 0.7770484835500691/1 [00:38<00:03, 14.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  45% 0.4512289581550658/1 [00:38<00:10, 18.44s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  51% 0.5071398634042411/1 [00:38<00:07, 16.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  85% 0.8522562006724954/1 [00:38<00:01, 11.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  51% 0.5063898542479381/1 [00:38<00:06, 13.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  57% 0.5718732522413981/1 [00:38<00:05, 11.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  57% 0.5650784820676802/1 [00:38<00:04,  9.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  64% 0.6358668309204162/1 [00:38<00:03,  8.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  92% 0.9198256340246754/1 [00:38<00:00,  9.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  62% 0.6228050012346396/1 [00:38<00:02,  7.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  70% 0.6991205994412952/1 [00:38<00:01,  6.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  98% 0.9812256843316562/1 [00:38<00:00,  7.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  68% 0.6792487088645554/1 [00:38<00:01,  5.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  77% 0.7679229441482164/1 [00:38<00:01,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  75% 0.7510861549389938/1 [00:38<00:01,  4.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  86% 0.8611390240737223/1 [00:38<00:00,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  85% 0.848579831754303/1 [00:38<00:00,  2.91s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | :  97% 0.9654522563713125/1 [00:38<00:00,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | :  97% 0.9701262248891785/1 [00:38<00:00,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-dev-11.7 | 359.7 MB  | : 100% 1.0/1 [01:10<00:00, 10.13s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcublas-11.11.3.6  | 364.0 MB  | : 100% 1.0/1 [01:12<00:00,  9.17s/it]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcublas-dev-11.11. | 394.1 MB  | : 100% 1.0/1 [01:22<00:00,  8.63s/it]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [01:29<00:00,  4.56s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [01:30<00:00,  6.69s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-dev-11.8.0.86 | 144.5 MB  | : 100% 1.0/1 [01:46<00:00,  5.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-dev-10.9.0. | 275.8 MB  | : 100% 1.0/1 [02:03<00:00,  6.64s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [02:04<00:00,  4.47s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2021.4.0         | 142.6 MB  | : 100% 1.0/1 [02:07<00:00,  3.50s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvvp-11.8.87    | 114.4 MB  | : 100% 1.0/1 [02:14<00:00,  2.02s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "nsight-compute-2022. | 610.0 MB  | : 100% 1.0/1 [02:17<00:00,  7.91s/it]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [02:24<00:00,  2.89s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | : 100% 1.0/1 [02:26<00:00,  2.48s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nsight-11.8.86  | 113.6 MB  | : 100% 1.0/1 [02:26<00:00,  3.37s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | : 100% 1.0/1 [02:30<00:00,  3.08s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvcc-11.6.124   | 42.2 MB   | : 100% 1.0/1 [02:32<00:00,  2.54s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvdisasm-11.8.8 | 48.7 MB   | : 100% 1.0/1 [02:34<00:00,  2.03s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.0       | 1.28 GB   | : 100% 1.0/1 [05:24<00:00, 40.13s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/iti/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/honest_llama/condaenv.n6zlscva.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting git+https://github.com/davidbau/baukit (from -r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 8))\n",
            "  Cloning https://github.com/davidbau/baukit to /tmp/pip-req-build-mxskye2r\n",
            "  Resolved https://github.com/davidbau/baukit to commit 9d51abd51ebf29769aecc38c4cbef459b731a36e\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting git+https://github.com/google-research/bleurt (from -r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 9))\n",
            "  Cloning https://github.com/google-research/bleurt to /tmp/pip-req-build-6nmkxwnc\n",
            "  Resolved https://github.com/google-research/bleurt to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting git+https://github.com/sylinrl/TruthfulQA (from -r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 109))\n",
            "  Cloning https://github.com/sylinrl/TruthfulQA to /tmp/pip-req-build-otl4ykrl\n",
            "  Resolved https://github.com/sylinrl/TruthfulQA to commit fdd8ad1c0d00a478cf8b0bb41a3ad8378c16293b\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting absl-py==1.4.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 8.0 MB/s eta 0:00:00\n",
            "Collecting accelerate==0.21.0\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 244.2/244.2 kB 21.9 MB/s eta 0:00:00\n",
            "Collecting aiohttp==3.8.3\n",
            "  Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 62.7 MB/s eta 0:00:00\n",
            "Collecting aiosignal==1.3.1\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting array-record==0.2.0\n",
            "  Downloading array_record-0.2.0-py38-none-any.whl (3.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 95.7 MB/s eta 0:00:00\n",
            "Collecting astunparse==1.6.3\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting async-timeout==4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting cachetools==5.3.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting charset-normalizer==2.1.1\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting click==8.1.3\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 13.5 MB/s eta 0:00:00\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting contourpy==1.0.7\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.0/300.0 kB 35.8 MB/s eta 0:00:00\n",
            "Collecting cycler==0.11.0\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting dacite==1.8.1\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Collecting datasets==2.12.0\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 46.3 MB/s eta 0:00:00\n",
            "Collecting dill==0.3.6\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 15.3 MB/s eta 0:00:00\n",
            "Collecting dm-tree==0.1.8\n",
            "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.9/152.9 kB 20.7 MB/s eta 0:00:00\n",
            "Collecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.2/42.2 kB 5.7 MB/s eta 0:00:00\n",
            "Collecting et-xmlfile==1.1.0\n",
            "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting etils==1.3.0\n",
            "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.4/126.4 kB 17.9 MB/s eta 0:00:00\n",
            "Collecting evaluate==0.4.1\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 12.5 MB/s eta 0:00:00\n",
            "Collecting fairscale==0.4.13\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 31.5 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting fancy-einsum==0.0.3\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting filelock==3.8.0\n",
            "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Collecting fire==0.5.0\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 12.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting flatbuffers==23.5.8\n",
            "  Downloading flatbuffers-23.5.8-py2.py3-none-any.whl (26 kB)\n",
            "Collecting fonttools==4.39.4\n",
            "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 67.6 MB/s eta 0:00:00\n",
            "Collecting frozenlist==1.3.3\n",
            "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 20.7 MB/s eta 0:00:00\n",
            "Collecting fsspec==2022.11.0\n",
            "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.5/139.5 kB 18.8 MB/s eta 0:00:00\n",
            "Collecting future==0.18.3\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 840.9/840.9 kB 67.0 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting geotorch==0.3.0\n",
            "  Downloading geotorch-0.3.0-py3-none-any.whl (54 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.8/54.8 kB 6.4 MB/s eta 0:00:00\n",
            "Collecting gin-config==0.5.0\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.3/61.3 kB 8.9 MB/s eta 0:00:00\n",
            "Collecting google-auth==2.18.0\n",
            "  Downloading google_auth-2.18.0-py2.py3-none-any.whl (178 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.9/178.9 kB 21.8 MB/s eta 0:00:00\n",
            "Collecting google-auth-oauthlib==1.0.0\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-pasta==0.2.0\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 8.0 MB/s eta 0:00:00\n",
            "Collecting googleapis-common-protos==1.59.0\n",
            "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 223.6/223.6 kB 28.7 MB/s eta 0:00:00\n",
            "Collecting grpcio==1.54.0\n",
            "  Downloading grpcio-1.54.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 58.8 MB/s eta 0:00:00\n",
            "Collecting h5py==3.7.0\n",
            "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 75.6 MB/s eta 0:00:00\n",
            "Collecting hickle==5.0.2\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 107.9/107.9 kB 13.5 MB/s eta 0:00:00\n",
            "Collecting huggingface-hub==0.16.4\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 31.9 MB/s eta 0:00:00\n",
            "Collecting ipdb==0.13.9\n",
            "  Downloading ipdb-0.13.9.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting jax==0.4.9\n",
            "  Downloading jax-0.4.9.tar.gz (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 74.2 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting joblib==1.2.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 32.1 MB/s eta 0:00:00\n",
            "Collecting jsonlines==4.0.0\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 39.8 MB/s eta 0:00:00\n",
            "Collecting keyboard==0.13.5\n",
            "  Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.1/58.1 kB 7.8 MB/s eta 0:00:00\n",
            "Collecting kiwisolver==1.4.4\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 76.5 MB/s eta 0:00:00\n",
            "Collecting libclang==16.0.0\n",
            "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.9/22.9 MB 49.8 MB/s eta 0:00:00\n",
            "Collecting llvmlite==0.39.1\n",
            "  Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.6/34.6 MB 47.6 MB/s eta 0:00:00\n",
            "Collecting markdown==3.4.3\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 13.1 MB/s eta 0:00:00\n",
            "Collecting matplotlib==3.7.1\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 70.1 MB/s eta 0:00:00\n",
            "Collecting mesh-tensorflow==0.1.21\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.2/385.2 kB 40.9 MB/s eta 0:00:00\n",
            "Collecting ml-dtypes==0.1.0\n",
            "  Downloading ml_dtypes-0.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 25.7 MB/s eta 0:00:00\n",
            "Collecting multidict==6.0.3\n",
            "  Downloading multidict-6.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 16.5 MB/s eta 0:00:00\n",
            "Collecting multiprocess==0.70.14\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 18.3 MB/s eta 0:00:00\n",
            "Collecting nltk==3.8.1\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 64.8 MB/s eta 0:00:00\n",
            "Collecting numba==0.56.4\n",
            "  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 75.5 MB/s eta 0:00:00\n",
            "Collecting oauthlib==3.2.2\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 21.3 MB/s eta 0:00:00\n",
            "Collecting openai==0.25.0\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.9/44.9 kB 6.2 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting openpyxl==3.0.10\n",
            "  Downloading openpyxl-3.0.10-py2.py3-none-any.whl (242 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.1/242.1 kB 29.9 MB/s eta 0:00:00\n",
            "Collecting opt-einsum==3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 8.3 MB/s eta 0:00:00\n",
            "Collecting pandas==2.0.1\n",
            "  Downloading pandas-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 74.2 MB/s eta 0:00:00\n",
            "Collecting pandas-stubs==1.5.1.221024\n",
            "  Downloading pandas_stubs-1.5.1.221024-py3-none-any.whl (144 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.5/144.5 kB 19.1 MB/s eta 0:00:00\n",
            "Collecting parallelformers==1.2.7\n",
            "  Downloading parallelformers-1.2.7.tar.gz (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 7.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting peft==0.5.0\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 12.1 MB/s eta 0:00:00\n",
            "Collecting plotly==5.14.1\n",
            "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 64.4 MB/s eta 0:00:00\n",
            "Collecting portalocker==2.7.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting promise==2.3\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting protobuf==4.23.0\n",
            "  Downloading protobuf-4.23.0-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 304.5/304.5 kB 32.1 MB/s eta 0:00:00\n",
            "Collecting pyarrow==10.0.1\n",
            "  Downloading pyarrow-10.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.0/36.0 MB 45.9 MB/s eta 0:00:00\n",
            "Collecting pyasn1==0.5.0\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.9/83.9 kB 11.8 MB/s eta 0:00:00\n",
            "Collecting pyasn1-modules==0.3.0\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 22.6 MB/s eta 0:00:00\n",
            "Collecting pynndescent==0.5.8\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 65.6 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pyyaml==6.0\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 60.3 MB/s eta 0:00:00\n",
            "Collecting regex==2022.10.31\n",
            "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 772.3/772.3 kB 25.5 MB/s eta 0:00:00\n",
            "Collecting requests-oauthlib==1.3.1\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting responses==0.18.0\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting rouge-score==0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting rsa==4.9\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting sacrebleu==2.3.1\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.9/118.9 kB 15.9 MB/s eta 0:00:00\n",
            "Collecting sacremoses==0.0.53\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 880.6/880.6 kB 69.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting safetensors==0.3.1\n",
            "  Downloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 75.5 MB/s eta 0:00:00\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 72.4 MB/s eta 0:00:00\n",
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 47.3 MB/s eta 0:00:00\n",
            "Collecting seaborn==0.12.2\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.3/293.3 kB 29.9 MB/s eta 0:00:00\n",
            "Collecting t5==0.7.1\n",
            "  Downloading t5-0.7.1-py3-none-any.whl (172 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.7/172.7 kB 21.1 MB/s eta 0:00:00\n",
            "Collecting tabulate==0.9.0\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting tenacity==8.2.2\n",
            "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Collecting tensorboard==2.12.3\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 106.6 MB/s eta 0:00:00\n",
            "Collecting tensorboard-data-server==0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 97.8 MB/s eta 0:00:00\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 585.9/585.9 MB 2.9 MB/s eta 0:00:00\n",
            "Collecting tensorflow-datasets==4.9.2\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 39.3 MB/s eta 0:00:00\n",
            "Collecting tensorflow-estimator==2.12.0\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 440.7/440.7 kB 47.3 MB/s eta 0:00:00\n",
            "Collecting tensorflow-hub==0.13.0\n",
            "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.6/100.6 kB 13.8 MB/s eta 0:00:00\n",
            "Collecting tensorflow-io-gcs-filesystem==0.32.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 85.0 MB/s eta 0:00:00\n",
            "Collecting tensorflow-metadata==1.13.1\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "Collecting tensorflow-text==2.12.1\n",
            "  Downloading tensorflow_text-2.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 10.0 MB/s eta 0:00:00\n",
            "Collecting termcolor==2.2.0\n",
            "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting tf-slim==1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 352.1/352.1 kB 38.1 MB/s eta 0:00:00\n",
            "Collecting tfds-nightly==4.9.2.dev202305230044\n",
            "  Downloading tfds_nightly-4.9.2.dev202305230044-py3-none-any.whl (5.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 87.3 MB/s eta 0:00:00\n",
            "Collecting threadpoolctl==3.1.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting tokenizers==0.15.0\n",
            "  Downloading tokenizers-0.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 94.0 MB/s eta 0:00:00\n",
            "Collecting toml==0.10.2\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 9.8 MB/s eta 0:00:00\n",
            "Collecting transformers==4.35.2\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 109.0 MB/s eta 0:00:00\n",
            "Collecting types-pytz==2022.6.0.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Collecting tzdata==2023.3\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 34.7 MB/s eta 0:00:00\n",
            "Collecting umap-learn==0.5.3\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.2/88.2 kB 12.0 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting werkzeug==2.3.4\n",
            "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 25.8 MB/s eta 0:00:00\n",
            "Collecting wrapt==1.14.1\n",
            "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 10.4 MB/s eta 0:00:00\n",
            "Collecting xxhash==3.1.0\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 kB 26.0 MB/s eta 0:00:00\n",
            "Collecting yarl==1.8.2\n",
            "  Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 262.1/262.1 kB 28.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from accelerate==0.21.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/envs/iti/lib/python3.8/site-packages (from accelerate==0.21.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 2)) (1.23.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from accelerate==0.21.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 2)) (1.13.0)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/iti/lib/python3.8/site-packages (from accelerate==0.21.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 2)) (5.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from aiohttp==3.8.3->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 3)) (22.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from astunparse==1.6.3->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 6)) (0.37.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from astunparse==1.6.3->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 17)) (2.28.1)\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 20.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: urllib3<2.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from google-auth==2.18.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 36)) (1.26.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/envs/iti/lib/python3.8/site-packages (from huggingface-hub==0.16.4->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 43)) (4.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/iti/lib/python3.8/site-packages (from ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (65.5.0)\n",
            "Requirement already satisfied: ipython>=7.17.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (8.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/iti/lib/python3.8/site-packages (from ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (5.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/envs/iti/lib/python3.8/site-packages (from markdown==3.4.3->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 53)) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from matplotlib==3.7.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 54)) (5.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from matplotlib==3.7.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 54)) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from matplotlib==3.7.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 54)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/envs/iti/lib/python3.8/site-packages (from matplotlib==3.7.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 54)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from pandas==2.0.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 65)) (2022.1)\n",
            "Requirement already satisfied: lxml in /usr/local/envs/iti/lib/python3.8/site-packages (from sacrebleu==2.3.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 83)) (4.9.1)\n",
            "Requirement already satisfied: babel in /usr/local/envs/iti/lib/python3.8/site-packages (from t5==0.7.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 89)) (2.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/envs/iti/lib/python3.8/site-packages (from t5==0.7.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 89)) (0.1.95)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from werkzeug==2.3.4->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 113)) (2.1.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from yarl==1.8.2->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 116)) (3.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/envs/iti/lib/python3.8/site-packages (from baukit==0.0.1->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 8)) (0.14.0)\n",
            "Requirement already satisfied: zipp in /usr/local/envs/iti/lib/python3.8/site-packages (from etils==1.3.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 22)) (3.8.0)\n",
            "  Downloading fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 171.9/171.9 kB 20.4 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.9/170.9 kB 19.4 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 169.0/169.0 kB 20.9 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.9/168.9 kB 20.0 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.9/168.9 kB 19.1 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.4/166.4 kB 19.2 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.4/173.4 kB 21.1 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.9.1-py3-none-any.whl (173 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.4/173.4 kB 20.3 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.2/173.2 kB 21.7 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 19.8 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.1/160.1 kB 20.0 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.0/154.0 kB 19.1 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 145.4/145.4 kB 17.5 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.0/143.0 kB 17.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pickleshare in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.18.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (5.1.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.1.6)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (2.11.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (3.0.20)\n",
            "Requirement already satisfied: backcall in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/iti/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.12.0->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 17)) (2022.12.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/envs/iti/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/iti/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.2.5)\n",
            "Requirement already satisfied: asttokens in /usr/local/envs/iti/lib/python3.8/site-packages (from stack-data->ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (2.0.5)\n",
            "Requirement already satisfied: executing in /usr/local/envs/iti/lib/python3.8/site-packages (from stack-data->ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.8.3)\n",
            "Requirement already satisfied: pure-eval in /usr/local/envs/iti/lib/python3.8/site-packages (from stack-data->ipython>=7.17.0->ipdb==0.13.9->-r /content/honest_llama/condaenv.n6zlscva.requirements.txt (line 44)) (0.2.2)\n",
            "Building wheels for collected packages: fairscale, fire, future, ipdb, jax, openai, parallelformers, promise, pynndescent, rouge-score, sacremoses, umap-learn, baukit, BLEURT, truthfulqa\n",
            "  Building wheel for fairscale (pyproject.toml): started\n",
            "  Building wheel for fairscale (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=9fd5bb8580e1c869c16f9252f8198ce4c7330f89d30f207f62d9247692a20788\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/02/9b/dc7d4ff5145afdd28f456dae6605a46619af0370eca30d8d7e\n",
            "  Building wheel for fire (setup.py): started\n",
            "  Building wheel for fire (setup.py): finished with status 'done'\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116933 sha256=d70b8c7c6b36c87254ce1b2cb0129ea9afad22c8f738eeb69b8fa731f3bea8fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=2856f8dbda46faec4656a22ab28b3da669fdfefe1bd36d9a8808d48aab8733c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
            "  Building wheel for ipdb (setup.py): started\n",
            "  Building wheel for ipdb (setup.py): finished with status 'done'\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11628 sha256=0aa3372aca722432f5deb3834137c433d8d31d8237962c49ba255cc3aed0b1be\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/51/8c/3dceedacfd0f743f3736b3840d08b6746b6259deea98207ba4\n",
            "  Building wheel for jax (pyproject.toml): started\n",
            "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for jax: filename=jax-0.4.9-py3-none-any.whl size=1477704 sha256=fa9379bb52881e85c9f67e1b070401ade2c23cf2697656e9a6801fee75420e49\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/43/61/f07ddc82e6b3e002bc38d095ca673476fcd7672538d88d88fe\n",
            "  Building wheel for openai (pyproject.toml): started\n",
            "  Building wheel for openai (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55848 sha256=caf6a5de121462fd005dd0a41f5ca386d4ac989fe1ef267b0cb5552191b60fb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "  Building wheel for parallelformers (setup.py): started\n",
            "  Building wheel for parallelformers (setup.py): finished with status 'done'\n",
            "  Created wheel for parallelformers: filename=parallelformers-1.2.7-py3-none-any.whl size=117771 sha256=9ddccccb1ed2b4a83b9976d78f85098c79bcbdf5a61b622ef96d5c5b6f73d90f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/dd/e5/4d1ffb7e3c62f142e624bf1e520c5dc7d4e5eac7bbab0e48d1\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=5ea96fc313b10da8f30772c5a64cf7abfd69ae11641e6da355abb3f4687d967b\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
            "  Building wheel for pynndescent (setup.py): started\n",
            "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55496 sha256=d9fa9dab96ed122043b3b4994299d59679180c94950f9adab71556d694f3d695\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "  Building wheel for rouge-score (setup.py): started\n",
            "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=2c8ae30e7cbed3092caa1a9e7ea0b9a8e3b6c37a44c12e5a7cf776205126359c\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=3d7a6fa3d71466ad3851bd545fdedb8ab278a21daa266c5df6dfe79da6c66dee\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for umap-learn (setup.py): started\n",
            "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82814 sha256=6b46511f55a536c631dec593798ed5fd8fd9d5f29ce32278f6a18587555a9396\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3a/67/06a8950e053725912e6a8c42c4a3a241410f6487b8402542ea\n",
            "  Building wheel for baukit (pyproject.toml): started\n",
            "  Building wheel for baukit (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for baukit: filename=baukit-0.0.1-py3-none-any.whl size=59675 sha256=8ac6d85bb4f5ae927768eb09acdb84b7450ec09c2f01841261bfeb21991bf327\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ospbtkjy/wheels/95/31/ad/dc51ee88e315aa7aa9462a1ffe3b38adf099be1324e7e4d7af\n",
            "  Building wheel for BLEURT (setup.py): started\n",
            "  Building wheel for BLEURT (setup.py): finished with status 'done'\n",
            "  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456765 sha256=1d841b9240a72c228b0e89441475593cc81c0a9e76fead869f60e40f900c83ed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ospbtkjy/wheels/b4/de/33/0ee3287cd60d8d65f0641a65e594986d4c6201003e39e91c23\n",
            "  Building wheel for truthfulqa (setup.py): started\n",
            "  Building wheel for truthfulqa (setup.py): finished with status 'done'\n",
            "  Created wheel for truthfulqa: filename=truthfulqa-0.0.1-py3-none-any.whl size=18585 sha256=4f205cb33e2568a4a1ee6b80e226bb3d6a30c5ebb036c3cc9fb6dbd82b5f691a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ospbtkjy/wheels/cd/6f/33/e1138416b3f4f7202347c107425a1e64fbf61a49f3b4b7240d\n",
            "Successfully built fairscale fire future ipdb jax openai parallelformers promise pynndescent rouge-score sacremoses umap-learn baukit BLEURT truthfulqa\n",
            "Installing collected packages: types-pytz, truthfulqa, safetensors, libclang, keyboard, gin-config, flatbuffers, dm-tree, xxhash, wrapt, werkzeug, tzdata, tqdm, toml, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tenacity, tabulate, scipy, regex, pyyaml, pyasn1, pyarrow, protobuf, promise, portalocker, pandas-stubs, opt-einsum, oauthlib, multidict, ml-dtypes, llvmlite, kiwisolver, keras, jsonlines, joblib, h5py, grpcio, google-pasta, gast, future, fsspec, frozenlist, fonttools, filelock, fancy-einsum, etils, et-xmlfile, einops, dill, dacite, cycler, contourpy, colorama, click, charset-normalizer, cachetools, async-timeout, astunparse, absl-py, yarl, tf-slim, tensorflow-hub, scikit-learn, sacremoses, sacrebleu, rsa, pyasn1-modules, plotly, pandas, openpyxl, numba, nltk, multiprocess, mesh-tensorflow, matplotlib, markdown, jax, hickle, googleapis-common-protos, geotorch, fire, fairscale, aiosignal, accelerate, tensorflow-metadata, seaborn, rouge-score, responses, requests-oauthlib, pynndescent, openai, huggingface-hub, google-auth, aiohttp, umap-learn, tokenizers, ipdb, google-auth-oauthlib, baukit, array-record, transformers, tfds-nightly, tensorflow-datasets, tensorboard, datasets, tensorflow, peft, parallelformers, evaluate, tensorflow-text, BLEURT, t5\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.4\n",
            "    Uninstalling charset-normalizer-2.0.4:\n",
            "      Successfully uninstalled charset-normalizer-2.0.4\n",
            "Successfully installed BLEURT-0.0.2 absl-py-1.4.0 accelerate-0.21.0 aiohttp-3.8.3 aiosignal-1.3.1 array-record-0.2.0 astunparse-1.6.3 async-timeout-4.0.2 baukit-0.0.1 cachetools-5.3.0 charset-normalizer-2.1.1 click-8.1.3 colorama-0.4.6 contourpy-1.0.7 cycler-0.11.0 dacite-1.8.1 datasets-2.12.0 dill-0.3.6 dm-tree-0.1.8 einops-0.6.1 et-xmlfile-1.1.0 etils-1.3.0 evaluate-0.4.1 fairscale-0.4.13 fancy-einsum-0.0.3 filelock-3.8.0 fire-0.5.0 flatbuffers-23.5.8 fonttools-4.39.4 frozenlist-1.3.3 fsspec-2022.11.0 future-0.18.3 gast-0.4.0 geotorch-0.3.0 gin-config-0.5.0 google-auth-2.18.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 googleapis-common-protos-1.59.0 grpcio-1.54.0 h5py-3.7.0 hickle-5.0.2 huggingface-hub-0.16.4 ipdb-0.13.9 jax-0.4.9 joblib-1.2.0 jsonlines-4.0.0 keras-2.12.0 keyboard-0.13.5 kiwisolver-1.4.4 libclang-16.0.0 llvmlite-0.39.1 markdown-3.4.3 matplotlib-3.7.1 mesh-tensorflow-0.1.21 ml-dtypes-0.1.0 multidict-6.0.3 multiprocess-0.70.14 nltk-3.8.1 numba-0.56.4 oauthlib-3.2.2 openai-0.25.0 openpyxl-3.0.10 opt-einsum-3.3.0 pandas-2.0.1 pandas-stubs-1.5.1.221024 parallelformers-1.2.7 peft-0.5.0 plotly-5.14.1 portalocker-2.7.0 promise-2.3 protobuf-4.23.0 pyarrow-10.0.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 pynndescent-0.5.8 pyyaml-6.0 regex-2022.10.31 requests-oauthlib-1.3.1 responses-0.18.0 rouge-score-0.1.2 rsa-4.9 sacrebleu-2.3.1 sacremoses-0.0.53 safetensors-0.3.1 scikit-learn-1.2.2 scipy-1.10.1 seaborn-0.12.2 t5-0.7.1 tabulate-0.9.0 tenacity-8.2.2 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-datasets-4.9.2 tensorflow-estimator-2.12.0 tensorflow-hub-0.13.0 tensorflow-io-gcs-filesystem-0.32.0 tensorflow-metadata-1.13.1 tensorflow-text-2.12.1 termcolor-2.2.0 tf-slim-1.1.0 tfds-nightly-4.9.2.dev202305230044 threadpoolctl-3.1.0 tokenizers-0.15.0 toml-0.10.2 tqdm-4.64.1 transformers-4.35.2 truthfulqa-0.0.1 types-pytz-2022.6.0.1 tzdata-2023.3 umap-learn-0.5.3 werkzeug-2.3.4 wrapt-1.14.1 xxhash-3.1.0 yarl-1.8.2\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate iti\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda env create -f environment.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8hfkjZLQdLk",
        "outputId": "3c2dd51f-a047-4aae-cc30-87783de01be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/envs/iti/lib/python3.8/site-packages (6.15.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (23.2.0)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (5.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (1.5.1)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (8.6.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (1.5.5)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (21.3)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (6.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (0.1.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipykernel) (7.4.7)\n",
            "Requirement already satisfied: backcall in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (3.0.20)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (2.11.2)\n",
            "Requirement already satisfied: stack-data in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/iti/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/envs/iti/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/envs/iti/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/envs/iti/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (4.11.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/envs/iti/lib/python3.8/site-packages (from packaging->ipykernel) (3.0.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/envs/iti/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/envs/iti/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/iti/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.23.1->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/iti/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Requirement already satisfied: asttokens in /usr/local/envs/iti/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /usr/local/envs/iti/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
            "Requirement already satisfied: executing in /usr/local/envs/iti/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.8.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "pip install ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmCSWerBQmxA",
        "outputId": "1073d0fa-ad03-4afa-9572-099704009bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed kernelspec iti in /root/.local/share/jupyter/kernels/iti\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "python -m ipykernel install --user --name iti --display-name \"iti\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ECE3iEr2Q1wP"
      },
      "outputs": [],
      "source": [
        "!mkdir -p validation/results_dump/answer_dump\n",
        "!mkdir -p validation/results_dump/summary_dump\n",
        "!mkdir -p validation/splits\n",
        "!mkdir features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FaY7tQ-RCUb"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "git clone https://github.com/sylinrl/TruthfulQA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtRTCZRlPoYq"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "# QLoRa requirements\n",
        "# pip install -q -U bitsandbytes\n",
        "pip install -i https://test.pypi.org/simple/ bitsandbytes==0.39.0\n",
        "# pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "# pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "# pip install -q -U git+https://github.com/huggingface/accelerate.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EUi93YfQ-GpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c04648-206a-4235-d48f-dd8273446482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDsQ-TBQRFYA"
      },
      "source": [
        "## Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GZP0JVICoYLN"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "# python get_activations.py llama_7B tqa_gen --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_activations.py alpaca_7B tqa_gen --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_activations.py vicuna_7B tqa_gen --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_activations.py llama_7B nq --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_activations.py llama_13B tqa_gen --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_activations.py flan_33B counselling --file_name annomi_greedy_responses_500  --device 0 --model_cache_dir model_cache/flan_33B --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_activations.py llama_7B tqa_gen --token answer_all --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_activations.py llama_7B tqa_gen --mlp_l1 Yes --token answer_all --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_activations.py llama_7B tqa_gen --mlp_l1 Yes --token last --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_activations.py llama_7B nq_open --token all --file_name nq_open_greedy_responses_1800  --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_activations.py llama_7B nq_open --mlp_l1 Yes --token all --file_name nq_open_greedy_responses_1800  --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_activations.py llama_7B cnn_dailymail --token prompt_last_onwards --file_name cnn_dailymail_greedy_responses_1000  --device 0 --save_path /content/gdrive/MyDrive/honest_llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRGTvLN7x_Px"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "# python get_prompt_responses_mi.py llama_7B --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_prompt_responses_mi.py flan_33B --device 0 --model_cache_dir model_cache/flan_33B --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_prompt_responses_factual.py llama_7B nq_open --device 0 --save_path /content/gdrive/MyDrive/honest_llama # 1800 validation\n",
        "# python get_prompt_responses_factual.py llama_7B cnn_dailymail --device 0 --save_path /content/gdrive/MyDrive/honest_llama # 1000 validation\n",
        "# python get_prompt_responses_factual.py llama_7B trivia_qa --device 0 --save_path /content/gdrive/MyDrive/honest_llama # 500 train\n",
        "python get_prompt_responses_factual.py llama_7B trivia_qa --len_dataset 1500 --start_at 500 --use_split train --device 0 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python get_prompt_responses_factual.py alpaca_7B nq_open --device 0 --save_path /content/gdrive/MyDrive/honest_llama # 1800 validation\n",
        "# python get_prompt_responses_factual.py alpaca_7B nq_open --len_dataset 5000 --start_at 0 --use_split train --device 0 --save_path ~/Desktop/honest_llama_data\n",
        "\n",
        "# python get_prompt_responses_factual.py llama_7B nq_open --len_dataset 3000 --start_at 0 --use_split train --device 0 --save_path ~/honest_llama_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Code completed')"
      ],
      "metadata": {
        "id": "G5QecBt-NhLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "\n",
        "# python get_uncertainty_scores.py llama_7B nq_open --device 0 --file_name greedy_responses_1800 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python get_uncertainty_scores.py llama_7B cnn_dailymail --device 0 --file_name greedy_responses_1000 --save_path /content/gdrive/MyDrive/honest_llama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ALAvU3vxBTTK",
        "outputId": "df021bca-594c-42d3-c57a-91590360cbd7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/envs/iti/lib/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
            "CUDA SETUP: Detected CUDA version 116\n",
            "CUDA SETUP: Loading binary /usr/local/envs/iti/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...\n",
            "Loading model..\n",
            "Loading model responses..\n",
            "Getting token probability scores..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-15 21:51:12.208083: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-03-15 21:51:12.267705: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-15 21:51:13.102856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/envs/iti/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/envs/iti/lib/libcudart.so.11.0'), PosixPath('/usr/local/envs/iti/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "You are using the default legacy behaviour of the <class 'llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
            "\rLoading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\rLoading checkpoint shards:   3%|▎         | 1/33 [00:00<00:15,  2.02it/s]\rLoading checkpoint shards:   6%|▌         | 2/33 [00:00<00:15,  2.02it/s]\rLoading checkpoint shards:   9%|▉         | 3/33 [00:01<00:14,  2.01it/s]\rLoading checkpoint shards:  12%|█▏        | 4/33 [00:01<00:14,  2.01it/s]\rLoading checkpoint shards:  15%|█▌        | 5/33 [00:02<00:13,  2.01it/s]\rLoading checkpoint shards:  18%|█▊        | 6/33 [00:02<00:13,  2.01it/s]\rLoading checkpoint shards:  21%|██        | 7/33 [00:03<00:12,  2.02it/s]\rLoading checkpoint shards:  24%|██▍       | 8/33 [00:03<00:12,  2.02it/s]\rLoading checkpoint shards:  27%|██▋       | 9/33 [00:04<00:11,  2.02it/s]\rLoading checkpoint shards:  30%|███       | 10/33 [00:04<00:11,  2.02it/s]\rLoading checkpoint shards:  33%|███▎      | 11/33 [00:05<00:10,  2.01it/s]\rLoading checkpoint shards:  36%|███▋      | 12/33 [00:05<00:10,  2.01it/s]\rLoading checkpoint shards:  39%|███▉      | 13/33 [00:06<00:09,  2.01it/s]\rLoading checkpoint shards:  42%|████▏     | 14/33 [00:06<00:09,  2.01it/s]\rLoading checkpoint shards:  45%|████▌     | 15/33 [00:07<00:08,  2.01it/s]\rLoading checkpoint shards:  48%|████▊     | 16/33 [00:07<00:08,  2.01it/s]\rLoading checkpoint shards:  52%|█████▏    | 17/33 [00:08<00:07,  2.01it/s]\rLoading checkpoint shards:  55%|█████▍    | 18/33 [00:08<00:07,  2.01it/s]\rLoading checkpoint shards:  58%|█████▊    | 19/33 [00:09<00:06,  2.02it/s]\rLoading checkpoint shards:  61%|██████    | 20/33 [00:09<00:06,  2.01it/s]\rLoading checkpoint shards:  64%|██████▎   | 21/33 [00:10<00:05,  2.01it/s]\rLoading checkpoint shards:  67%|██████▋   | 22/33 [00:10<00:05,  2.01it/s]\rLoading checkpoint shards:  70%|██████▉   | 23/33 [00:11<00:04,  2.01it/s]\rLoading checkpoint shards:  73%|███████▎  | 24/33 [00:11<00:04,  2.01it/s]\rLoading checkpoint shards:  76%|███████▌  | 25/33 [00:12<00:03,  2.01it/s]\rLoading checkpoint shards:  79%|███████▉  | 26/33 [00:12<00:03,  2.01it/s]\rLoading checkpoint shards:  82%|████████▏ | 27/33 [00:13<00:02,  2.02it/s]\rLoading checkpoint shards:  85%|████████▍ | 28/33 [00:13<00:02,  2.02it/s]\rLoading checkpoint shards:  88%|████████▊ | 29/33 [00:14<00:01,  2.01it/s]\rLoading checkpoint shards:  91%|█████████ | 30/33 [00:14<00:01,  2.02it/s]\rLoading checkpoint shards:  94%|█████████▍| 31/33 [00:15<00:00,  2.01it/s]\rLoading checkpoint shards:  97%|█████████▋| 32/33 [00:15<00:00,  2.01it/s]\rLoading checkpoint shards: 100%|██████████| 33/33 [00:16<00:00,  1.90it/s]\rLoading checkpoint shards: 100%|██████████| 33/33 [00:16<00:00,  2.00it/s]\n",
            "\r0it [00:00, ?it/s]\r1it [00:00,  3.88it/s]\r1it [00:00,  2.70it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"get_uncertainty_scores.py\", line 88, in <module>\n",
            "    main()\n",
            "  File \"get_uncertainty_scores.py\", line 78, in main\n",
            "    model_output = model(tokenized_input, labels=target_ids, output_hidden_states=True)\n",
            "  File \"/usr/local/envs/iti/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/honest_llama/llama/modeling_llama.py\", line 1044, in forward\n",
            "    outputs = self.model(\n",
            "  File \"/usr/local/envs/iti/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/honest_llama/llama/modeling_llama.py\", line 932, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "  File \"/usr/local/envs/iti/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/honest_llama/llama/modeling_llama.py\", line 679, in forward\n",
            "    hidden_states = self.input_layernorm(hidden_states)\n",
            "  File \"/usr/local/envs/iti/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/honest_llama/llama/modeling_llama.py\", line 106, in forward\n",
            "    hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 39.56 GiB total capacity; 38.05 GiB already allocated; 24.81 MiB free; 38.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'source activate iti\\n\\n# python get_uncertainty_scores.py llama_7B nq_open --device 0 --file_name greedy_responses_1800 --save_path /content/gdrive/MyDrive/honest_llama\\npython get_uncertainty_scores.py llama_7B cnn_dailymail --device 0 --file_name greedy_responses_1000 --save_path /content/gdrive/MyDrive/honest_llama\\n'' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2c2fc767140c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'source activate iti\\n\\n# python get_uncertainty_scores.py llama_7B nq_open --device 0 --file_name greedy_responses_1800 --save_path /content/gdrive/MyDrive/honest_llama\\npython get_uncertainty_scores.py llama_7B cnn_dailymail --device 0 --file_name greedy_responses_1000 --save_path /content/gdrive/MyDrive/honest_llama\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'source activate iti\\n\\n# python get_uncertainty_scores.py llama_7B nq_open --device 0 --file_name greedy_responses_1800 --save_path /content/gdrive/MyDrive/honest_llama\\npython get_uncertainty_scores.py llama_7B cnn_dailymail --device 0 --file_name greedy_responses_1000 --save_path /content/gdrive/MyDrive/honest_llama\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5tkuqifLY5K"
      },
      "source": [
        "## Analysis - TruthfulQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0F3z_4BQSEF"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "cd validation\n",
        "\n",
        "# python mlp_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes vote_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes lr_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes vote_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py llama_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes lr_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python mlp_probe.py alpaca_7B --dataset_name tqa_gen --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py alpaca_7B --dataset_name tqa_gen --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe.py alpaca_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py alpaca_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python mlp_probe.py vicuna_7B --dataset_name tqa_gen --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py vicuna_7B --dataset_name tqa_gen --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe.py vicuna_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py vicuna_7B --dataset_name tqa_gen --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YWhJwtPC2p1"
      },
      "source": [
        "### Ind and Single Probes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oAFyy6UMgOB",
        "outputId": "61a9908d-1e95-4d94-9fcb-48b1e5d0d756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP best probe acc:  0.8100344980562009  Layer 11\n",
            "AH best probe acc:  0.7894100890761993 Layer: 11.0 Head: 3\n",
            "Best head truth var: 0.006615\n",
            "Best head false var: 0.00657\n",
            "\n",
            "\n",
            "MLP avg probe acc:  0.7443043183861213\n",
            "AH avg probe acc:  0.6381936549990077\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_ah_probe_accs.npy')\n",
        "truth_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_ah_probe_bestprobe_trueActsVar.npy')\n",
        "false_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_ah_probe_bestprobe_falseActsVar.npy')\n",
        "\n",
        "print('MLP best probe acc: ',np.max(np.mean(mlp_probe_accs, axis=0)), ' Layer', np.argmax(np.mean(mlp_probe_accs, axis=0)))\n",
        "head = np.argmax(np.mean(ah_probe_accs, axis=0))\n",
        "print('AH best probe acc: ',np.max(np.mean(ah_probe_accs, axis=0)), 'Layer:',np.floor(head/32), 'Head:',head%32)\n",
        "print('Best head truth var:',truth_var)\n",
        "print('Best head false var:',false_var)\n",
        "print('\\n')\n",
        "print('MLP avg probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH avg probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPnozrVUdMeg",
        "outputId": "aabf60ed-83be-405f-b316-afb12adcd29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP best probe acc:  0.7830547999579719  Layer 17\n",
            "AH best probe acc:  0.7816611602087395 Layer: 16.0 Head: 11\n",
            "Best head truth var: 0.05923\n",
            "Best head false var: 0.05356\n",
            "\n",
            "\n",
            "MLP avg probe acc:  0.7328788438189523\n",
            "AH avg probe acc:  0.6292309860749121\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/alpaca_7B_tqa_gen_2_ind_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/alpaca_7B_tqa_gen_2_ind_ah_probe_accs.npy')\n",
        "truth_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/alpaca_7B_tqa_gen_2_ind_ah_probe_bestprobe_trueActsVar.npy')\n",
        "false_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/alpaca_7B_tqa_gen_2_ind_ah_probe_bestprobe_falseActsVar.npy')\n",
        "\n",
        "print('MLP best probe acc: ',np.max(np.mean(mlp_probe_accs, axis=0)), ' Layer', np.argmax(np.mean(mlp_probe_accs, axis=0)))\n",
        "head = np.argmax(np.mean(ah_probe_accs, axis=0))\n",
        "print('AH best probe acc: ',np.max(np.mean(ah_probe_accs, axis=0)), 'Layer:',np.floor(head/32), 'Head:',head%32 )\n",
        "print('Best head truth var:',truth_var)\n",
        "print('Best head false var:',false_var)\n",
        "print('\\n')\n",
        "print('MLP avg probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH avg probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiCEMhy3mFxv",
        "outputId": "d336ec3a-d2de-4808-83a6-1a95a062e8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP best probe acc:  0.787819442660845  Layer 18\n",
            "AH best probe acc:  0.7806294290017162 Layer: 11.0 Head: 3\n",
            "Best head truth var: 0.00479\n",
            "Best head false var: 0.00423\n",
            "\n",
            "\n",
            "MLP avg probe acc:  0.7339353376694258\n",
            "AH avg probe acc:  0.6366175945445023\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/vicuna_7B_tqa_gen_2_ind_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/vicuna_7B_tqa_gen_2_ind_ah_probe_accs.npy')\n",
        "truth_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/vicuna_7B_tqa_gen_2_ind_ah_probe_bestprobe_trueActsVar.npy')\n",
        "false_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/vicuna_7B_tqa_gen_2_ind_ah_probe_bestprobe_falseActsVar.npy')\n",
        "\n",
        "print('MLP best probe acc: ',np.max(np.mean(mlp_probe_accs, axis=0)), ' Layer', np.argmax(np.mean(mlp_probe_accs, axis=0)))\n",
        "head = np.argmax(np.mean(ah_probe_accs, axis=0))\n",
        "print('AH best probe acc: ',np.max(np.mean(ah_probe_accs, axis=0)), 'Layer:',np.floor(head/32), 'Head:',head%32 )\n",
        "print('Best head truth var:',truth_var)\n",
        "print('Best head false var:',false_var)\n",
        "print('\\n')\n",
        "print('MLP avg probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH avg probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvbIxOcgvEz7",
        "outputId": "ae1289c7-9712-4dd0-b463-493cb6823350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP probe acc:  0.7941353304458479\n",
            "AH probe acc:  0.8438962956909535\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_ah_probe_accs.npy')\n",
        "\n",
        "print('MLP probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU_TthLZVoyu",
        "outputId": "1a0aef5c-b2cd-48f2-ab85-d222d276379d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP probe acc:  0.8125386716789054\n",
            "AH probe acc:  0.8364625774892887\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/alpaca_7B_tqa_gen_2_single_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/alpaca_7B_tqa_gen_2_single_ah_probe_accs.npy')\n",
        "\n",
        "print('MLP probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dONdU9TkVoZ7",
        "outputId": "8142c4ab-bf40-4969-cae2-c2dbbf19848c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP probe acc:  0.8051049534772406\n",
            "AH probe acc:  0.8424238532752724\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/vicuna_7B_tqa_gen_2_single_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/vicuna_7B_tqa_gen_2_single_ah_probe_accs.npy')\n",
        "\n",
        "print('MLP probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMAdQnKQC403"
      },
      "source": [
        "### Vote/LR over ind probes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUO0wBmuC5I2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_mlp_probe_accs.npy')\n",
        "print('MLP probe acc (vote over individual): ',np.mean(mlp_probe_accs))\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_lr_on_ind_mlp_probe_accs.npy')\n",
        "print('MLP probe acc (additional layer over individual): ',np.mean(mlp_probe_accs))\n",
        "\n",
        "print('\\n')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_ah_probe_accs.npy')\n",
        "print('AH probe acc (vote over individual): ',np.mean(ah_probe_accs))\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_lr_on_ind_ah_probe_accs.npy')\n",
        "print('AH probe acc (additional layer over individual): ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZfX3-zMDakX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_mlp_probe_accs.npy')\n",
        "# mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_nq_2_ind_mlp_probe_accs.npy')\n",
        "\n",
        "\n",
        "sns.heatmap(mlp_probe_accs, linewidth=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU8RY_NYDbIi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_ah_probe_accs.npy')\n",
        "# ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_nq_2_ind_ah_probe_accs.npy')\n",
        "\n",
        "print(ah_probe_accs.shape)\n",
        "# sns.heatmap(np.mean(ah_probe_accs,axis=0).reshape(32,32), linewidth=0.5)\n",
        "sns.heatmap(np.absolute(np.diff(ah_probe_accs,axis=0)).reshape(32,32), linewidth=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xTttmMuz08e"
      },
      "source": [
        "### Probe Coefs And Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfwZpFGvDbC9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "mlp_probe_coef = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_mlp_probe_coef.npy')\n",
        "\n",
        "mlp_probe_coef.shape\n",
        "mlp_probe_coef = mlp_probe_coef.reshape(2,32,4096)\n",
        "var = np.empty(mlp_probe_coef.shape[:2])\n",
        "for fold in [0,1]:\n",
        "    for layer in range(32):\n",
        "        var[fold,layer] = np.var(np.absolute(mlp_probe_coef[fold,layer,:]))\n",
        "\n",
        "# sns.heatmap(var, linewidth=0.5)\n",
        "\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_mlp_probe_accs.npy')\n",
        "print(np.corrcoef(mlp_probe_accs[0],var[0])[0,1])\n",
        "print(np.corrcoef(mlp_probe_accs[1],var[1])[0,1])\n",
        "\n",
        "for top_perc in [0.1,0.2,0.3,0.4,0.5]:\n",
        "    topx = int(mlp_probe_coef.shape[2]*top_perc)\n",
        "    val0_top = np.argsort(np.absolute(mlp_probe_coef[0][11]))[-topx:]\n",
        "    val1_top = np.argsort(np.absolute(mlp_probe_coef[1][11]))[-topx:]\n",
        "    print(top_perc,np.sum([1 for idx in val0_top if idx in val1_top])/topx)\n",
        "\n",
        "print('Single')\n",
        "mlp_probe_coef = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_mlp_probe_coef.npy')\n",
        "for fold in [0,1]:\n",
        "    print(np.var(np.absolute(mlp_probe_coef[fold,:])))\n",
        "\n",
        "for top_perc in [0.1,0.2,0.3,0.4,0.5]:\n",
        "    topx = int(mlp_probe_coef.shape[1]*top_perc)\n",
        "    val0_top = np.argsort(np.absolute(mlp_probe_coef[0]))[-topx:]\n",
        "    val1_top = np.argsort(np.absolute(mlp_probe_coef[1]))[-topx:]\n",
        "    print(top_perc,np.sum([1 for idx in val0_top if idx in val1_top])/topx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-RNDyZ5BCW3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "ah_probe_coef = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_ah_probe_coef.npy')\n",
        "\n",
        "ah_probe_coef.shape\n",
        "ah_probe_coef = ah_probe_coef.reshape(2,32,32,128)\n",
        "var = np.empty(ah_probe_coef.shape[:3])\n",
        "for fold in [0,1]:\n",
        "    for layer in range(32):\n",
        "        for head in range(32):\n",
        "            var[fold,layer,head] = np.var(np.absolute(ah_probe_coef[fold,layer,head,:]))\n",
        "\n",
        "# sns.heatmap(var[0], linewidth=0.5)\n",
        "# sns.heatmap(var[1], linewidth=0.5)\n",
        "\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_ind_ah_probe_accs.npy')\n",
        "print(np.corrcoef(ah_probe_accs[0],var[0].reshape(1024))[0,1])\n",
        "print(np.corrcoef(ah_probe_accs[1],var[1].reshape(1024))[0,1])\n",
        "\n",
        "for top_perc in [0.1,0.2,0.3,0.4,0.5]:\n",
        "    topx = int(ah_probe_coef.shape[3]*top_perc)\n",
        "    val0_top = np.argsort(np.absolute(ah_probe_coef[0][11][2]))[-topx:]\n",
        "    val1_top = np.argsort(np.absolute(ah_probe_coef[1][11][2]))[-topx:]\n",
        "    print(top_perc,np.sum([1 for idx in val0_top if idx in val1_top])/topx)\n",
        "\n",
        "print('Single')\n",
        "ah_probe_coef = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_ah_probe_coef.npy')\n",
        "for fold in [0,1]:\n",
        "    print(np.var(np.absolute(ah_probe_coef[fold,:])))\n",
        "\n",
        "for top_perc in [0.1,0.2,0.3,0.4,0.5]:\n",
        "    topx = int(ah_probe_coef.shape[1]*top_perc)\n",
        "    val0_top = np.argsort(np.absolute(ah_probe_coef[0]))[-topx:]\n",
        "    val1_top = np.argsort(np.absolute(ah_probe_coef[1]))[-topx:]\n",
        "    print(top_perc,np.sum([1 for idx in val0_top if idx in val1_top])/topx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akQzEJgEzU6t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "mlp_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_mlp_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_mlp_probe_true.npy',allow_pickle=True)\n",
        "\n",
        "ind_hard_samples = {}\n",
        "for fold in [0,1]:\n",
        "    ind_hard_samples[fold] = []\n",
        "    for i,sample_pred in enumerate(mlp_probe_pred[fold]):\n",
        "        # print(np.sum(np.argmax(sample_pred,axis=1)),y_true[fold][i])\n",
        "        if any(np.argmax(sample_pred,axis=1)==y_true[fold][i])==False:\n",
        "            ind_hard_samples[fold].append(i)\n",
        "print(len(ind_hard_samples[0]))\n",
        "print(len(ind_hard_samples[1]))\n",
        "\n",
        "print('Single')\n",
        "mlp_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_mlp_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_mlp_probe_true.npy',allow_pickle=True)\n",
        "hard_samples = {}\n",
        "for fold in [0,1]:\n",
        "    hard_samples[fold] = []\n",
        "    for i,sample_pred in enumerate(mlp_probe_pred[fold]):\n",
        "        if np.argmax(sample_pred)!=y_true[fold][i]:\n",
        "            hard_samples[fold].append(i)\n",
        "print(len(hard_samples[0]), sum([1 for sample in hard_samples[0] if sample in ind_hard_samples[0]]))\n",
        "print(len(hard_samples[1]), sum([1 for sample in hard_samples[1] if sample in ind_hard_samples[1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku5s-NyCzXD7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "ah_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_ah_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_ah_probe_true.npy',allow_pickle=True)\n",
        "ind_hard_samples = {}\n",
        "for fold in [0,1]:\n",
        "    ind_hard_samples[fold] = []\n",
        "    for i,sample_pred in enumerate(ah_probe_pred[fold]):\n",
        "        # print(np.sum(np.argmax(sample_pred,axis=1)),y_true[fold][i])\n",
        "        if any(np.argmax(sample_pred,axis=1)==y_true[fold][i])==False:\n",
        "            ind_hard_samples[fold].append(i)\n",
        "print(len(ind_hard_samples[0]))\n",
        "print(len(ind_hard_samples[1]))\n",
        "\n",
        "print('Single')\n",
        "ah_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_ah_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_single_ah_probe_true.npy',allow_pickle=True)\n",
        "hard_samples = {}\n",
        "for fold in [0,1]:\n",
        "    hard_samples[fold] = []\n",
        "    for i,sample_pred in enumerate(ah_probe_pred[fold]):\n",
        "        if np.argmax(sample_pred)!=y_true[fold][i]:\n",
        "            hard_samples[fold].append(i)\n",
        "print(len(hard_samples[0]), sum([1 for sample in hard_samples[0] if sample in ind_hard_samples[0]]))\n",
        "print(len(hard_samples[1]), sum([1 for sample in hard_samples[1] if sample in ind_hard_samples[1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho8qShFZ0W-h"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "# dataset = load_dataset(\"truthful_qa\", \"generation\", streaming= True)['validation']\n",
        "# len_dataset = 817\n",
        "dataset = load_dataset(\"OamPatel/iti_nq_open_val\", streaming= True)['validation']\n",
        "len_dataset = 3610\n",
        "actual_labels= []\n",
        "for val in list(dataset.take(len_dataset)):\n",
        "    # actual_labels.append([1 for ans in val['correct_answers']]+[0 for ans in val['incorrect_answers']])\n",
        "    actual_labels.append([1 for ans in val['answer']]+[0])\n",
        "idxs_to_split_at = np.cumsum([len(x) for x in actual_labels])\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "labels = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_nq_labels_11000.npy\")\n",
        "labels = list(labels)\n",
        "separated_labels = []\n",
        "for i in range(len(idxs_to_split_at)):\n",
        "    if i == 0:\n",
        "        separated_labels.append(labels[:idxs_to_split_at[i]])\n",
        "    else:\n",
        "        separated_labels.append(labels[idxs_to_split_at[i-1]:idxs_to_split_at[i]])\n",
        "assert separated_labels == actual_labels\n",
        "\n",
        "fold_idxs = np.array_split(np.arange(len_dataset), 2)\n",
        "for i in range(2):\n",
        "    train_idxs = np.concatenate([fold_idxs[j] for j in range(2) if j != i])\n",
        "    train_set_idxs = np.random.choice(train_idxs, size=int(len(train_idxs)*(1-0.2)), replace=False)\n",
        "    val_set_idxs = np.array([x for x in train_idxs if x not in train_set_idxs])\n",
        "    print(sum(np.concatenate([separated_labels[i] for i in train_set_idxs],axis=0)),len(train_set_idxs),sum(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0)),len(val_set_idxs))\n",
        "    tot = len(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0))\n",
        "    print('baseline accuracy:',max(sum(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0))\n",
        "                                  ,tot-sum(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0))\n",
        "                                  )/tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThKgGDNdO4G-"
      },
      "source": [
        "### Probe Confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm7MuSaLO_Az"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from collections import Counter\n",
        "mlp_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_mlp_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_mlp_probe_true.npy',allow_pickle=True)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 5))\n",
        "confident_probe, confident_sample_pred = {}, {}\n",
        "for fold in [0,1]:\n",
        "    confident_probe[fold], confident_sample_pred[fold] = [], []\n",
        "    for i,sample_pred in enumerate(mlp_probe_pred[fold]):\n",
        "        probe_wise_entropy = (-sample_pred*np.log2(sample_pred)).sum(axis=1)\n",
        "        confident_probe[fold].append(np.argmin(probe_wise_entropy))\n",
        "        confident_sample_pred[fold].append(np.argmax(sample_pred[np.argmin(probe_wise_entropy)]))\n",
        "    print(np.sum(y_true[fold]==confident_sample_pred[fold])/len(y_true[fold]), 'Layer:', statistics.mode(confident_probe[fold]))\n",
        "    axes[0,fold].hist(confident_probe[fold])\n",
        "    for top_num in range(2,10):\n",
        "      confident_sample_pred[fold] = []\n",
        "      for i,sample_pred in enumerate(mlp_probe_pred[fold]):\n",
        "          probe_wise_entropy = (-sample_pred*np.log2(sample_pred)).sum(axis=1)\n",
        "          top_probes = sorted(range(len(probe_wise_entropy)), key=lambda i: probe_wise_entropy[i])[-top_num:]\n",
        "          confident_sample_pred[fold].append(np.mean([np.argmax(sample_pred[probe,:]) for probe in top_probes]).astype(int))\n",
        "      print(top_num,np.sum(y_true[fold]==confident_sample_pred[fold])/len(y_true[fold]))\n",
        "# for fold in [0,1]:\n",
        "#     for top_num in range(2,10):\n",
        "#         top_probes = list(dict(Counter(confident_probe[fold]).most_common(top_num)))\n",
        "#         preds = np.vstack([np.argmax(mlp_probe_pred[fold][:,probe,:], axis=1) for probe in top_probes])\n",
        "#         preds = np.mean(preds, axis=0).astype(int) # Vote over top probes\n",
        "#         print(top_num, np.sum(preds==y_true[fold])/len(y_true[fold]))\n",
        "\n",
        "\n",
        "print('AH')\n",
        "ah_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_ah_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_tqa_gen_2_vote_on_ind_ah_probe_true.npy',allow_pickle=True)\n",
        "confident_probe, confident_sample_pred = {}, {}\n",
        "for fold in [0,1]:\n",
        "    confident_probe[fold], confident_sample_pred[fold] = [], []\n",
        "    for i,sample_pred in enumerate(ah_probe_pred[fold]):\n",
        "        probe_wise_entropy = (-sample_pred*np.log2(sample_pred)).sum(axis=1)\n",
        "        confident_probe[fold].append(np.argmin(probe_wise_entropy))\n",
        "        confident_sample_pred[fold].append(np.argmax(sample_pred[np.argmin(probe_wise_entropy)]))\n",
        "    best_probe = statistics.mode(confident_probe[fold])\n",
        "    print(np.sum(y_true[fold]==confident_sample_pred[fold])/len(y_true[fold]), best_probe,'Layer:', np.floor(best_probe/32), 'Head:', best_probe%32-1)\n",
        "    axes[1,fold].hist(confident_probe[fold])\n",
        "    for top_num in [2,5,10,20,50,100,200,300]:\n",
        "      confident_sample_pred[fold] = []\n",
        "      for i,sample_pred in enumerate(ah_probe_pred[fold]):\n",
        "          probe_wise_entropy = (-sample_pred*np.log2(sample_pred)).sum(axis=1)\n",
        "          top_probes = sorted(range(len(probe_wise_entropy)), key=lambda i: probe_wise_entropy[i])[-top_num:]\n",
        "          confident_sample_pred[fold].append(np.mean([np.argmax(sample_pred[probe,:]) for probe in top_probes]).astype(int))\n",
        "      print(top_num,np.sum(y_true[fold]==confident_sample_pred[fold])/len(y_true[fold]))\n",
        "# for fold in [0,1]:\n",
        "#     for top_num in [2,5,10,20,50,100,200,300]:\n",
        "#         top_probes = list(dict(Counter(confident_probe[fold]).most_common(top_num)))\n",
        "#         preds = np.vstack([np.argmax(ah_probe_pred[fold][:,probe,:], axis=1) for probe in top_probes])\n",
        "#         preds = np.mean(preds, axis=0).astype(int) # Vote over top probes\n",
        "#         print(top_num, np.sum(preds==y_true[fold])/len(y_true[fold]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj8P8455Vl4Q"
      },
      "source": [
        "### Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe47jHQEVnli"
      },
      "outputs": [],
      "source": [
        "def unit_vector(vector):\n",
        "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
        "    return vector / np.linalg.norm(vector)\n",
        "\n",
        "def angle_between(v1, v2):\n",
        "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
        "\n",
        "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
        "            1.5707963267948966\n",
        "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
        "            0.0\n",
        "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
        "            3.141592653589793\n",
        "    \"\"\"\n",
        "    v1_u = unit_vector(v1)\n",
        "    v2_u = unit_vector(v2)\n",
        "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTK4WoygVvs_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dataset_name = 'tqa_gen'\n",
        "file_ends = [1000,3000,4000,5000,6000] # tqa\n",
        "# file_ends = [1000,3000,5000,7000,9000,11000] # nq\n",
        "mlp_wise_activations = []\n",
        "for file_end in file_ends:\n",
        "    mlp_wise_activations.append(np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_mlp_wise_{file_end}.npy\"))\n",
        "mlp_wise_activations = np.concatenate(mlp_wise_activations, axis=0)\n",
        "assert mlp_wise_activations.shape[1:] == (32, 4096)\n",
        "labels = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_labels_{file_end}.npy\")\n",
        "assert len(labels)==len(mlp_wise_activations)\n",
        "\n",
        "# separated_mlp_wise_activations, separated_labels, idxs_to_split_at = get_separated_activations(labels, mlp_wise_activations, dataset_name)\n",
        "mlp_wise_activations.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwXmQKpAVwUF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "chosen_dims = {}\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 5))\n",
        "# fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 5),subplot_kw=dict(projection='3d'))\n",
        "for i,layer in enumerate([0,11]): # range(32):\n",
        "    layer_mlp_wise_activations = np.squeeze(mlp_wise_activations[:,layer,:])\n",
        "    # # layer_mlp_wise_activations = (layer_mlp_wise_activations - layer_mlp_wise_activations.min())/(layer_mlp_wise_activations.max() - layer_mlp_wise_activations.min()) # is it okay to normalise across all dimensions?\n",
        "    # truth_activations = np.vstack([layer_mlp_wise_activations[i,:] for i,label in enumerate(labels) if label==1])\n",
        "    # false_activations = np.vstack([layer_mlp_wise_activations[i,:] for i,label in enumerate(labels) if label==0])\n",
        "    # # print(layer,np.var(truth_activations),np.var(false_activations))\n",
        "    # print(layer,angle_between(np.mean(truth_activations,axis=0),np.mean(false_activations,axis=0)))\n",
        "    # act_diff = (np.max(truth_activations,axis=0)-np.max(false_activations,axis=0))/np.max(truth_activations,axis=0)\n",
        "    # counts, bins = np.histogram(act_diff)\n",
        "    # axes[i].stairs(counts, bins)\n",
        "    # print(len(np.argwhere(act_diff > 0.3)))\n",
        "    # chosen_dims[layer] = np.argwhere(act_diff > 0.3)\n",
        "\n",
        "    pca = PCA(n_components=3)\n",
        "    transformed = pd.DataFrame(pca.fit_transform(layer_mlp_wise_activations))\n",
        "    axes[i,0].scatter(transformed[labels==1][0], transformed[labels==1][1], label='Truthful', c='blue')\n",
        "    axes[i,0].scatter(transformed[labels==0][0], transformed[labels==0][1], label='Non-truthful', c='yellow')\n",
        "    axes[i,1].scatter(transformed[labels==1][0], transformed[labels==1][2], label='Truthful', c='blue')\n",
        "    axes[i,1].scatter(transformed[labels==0][0], transformed[labels==0][2], label='Non-truthful', c='yellow')\n",
        "    axes[i,2].scatter(transformed[labels==1][1], transformed[labels==1][2], label='Truthful', c='blue')\n",
        "    axes[i,2].scatter(transformed[labels==0][1], transformed[labels==0][2], label='Non-truthful', c='yellow')\n",
        "    # # 3d\n",
        "    # axes[i].scatter(transformed[labels==1][0], transformed[labels==1][1], transformed[labels==1][2], label='Truthful', c='blue')\n",
        "    # axes[i].scatter(transformed[labels==0][0], transformed[labels==0][1], transformed[labels==0][2], label='Non-truthful', c='yellow')\n",
        "    # break\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruhUKtUzN5ht"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 5))\n",
        "for i,layer in enumerate([0,11]):\n",
        "    layer_mlp_wise_activations = np.squeeze(mlp_wise_activations[:,layer,:])\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(layer_mlp_wise_activations)\n",
        "    print(tsne.kl_divergence_)\n",
        "    axes[i].scatter(x=X_tsne[labels==1, 0], y=X_tsne[labels==1, 1], color='blue')\n",
        "    axes[i].scatter(x=X_tsne[labels==0, 0], y=X_tsne[labels==0, 1], color='yellow')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwLkmnfsVwR8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dataset_name = 'tqa_gen'\n",
        "file_ends = [1000,3000,4000,5000,6000] # tqa\n",
        "# file_ends = [1000,3000,5000,7000,9000,11000] # nq\n",
        "head_wise_activations = []\n",
        "for file_end in file_ends:\n",
        "    head_wise_activations.append(np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_head_wise_{file_end}.npy\"))\n",
        "head_wise_activations = np.concatenate(head_wise_activations, axis=0)\n",
        "assert head_wise_activations.shape[1:] == (32, 4096)\n",
        "labels = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_labels_{file_end}.npy\")\n",
        "assert len(labels)==len(head_wise_activations)\n",
        "\n",
        "head_wise_activations = head_wise_activations.reshape(head_wise_activations.shape[0],32,32,128)\n",
        "head_wise_activations.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5HOViSGV_Mm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 5))\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 5),subplot_kw=dict(projection='3d'))\n",
        "for i,(layer,head) in enumerate([(0,0),(11,2)]): # range(32):\n",
        "    layer_head_wise_activations = np.squeeze(head_wise_activations[:,layer,head,:])\n",
        "    # truth_activations = np.vstack([layer_head_wise_activations[i,:] for i,label in enumerate(labels) if label==1])\n",
        "    # false_activations = np.vstack([layer_head_wise_activations[i,:] for i,label in enumerate(labels) if label==0])\n",
        "    # print(layer,head,angle_between(np.mean(truth_activations,axis=0),np.mean(false_activations,axis=0)))\n",
        "    # act_diff = (np.max(truth_activations,axis=0)-np.max(false_activations,axis=0))/np.max(truth_activations,axis=0)\n",
        "    # counts, bins = np.histogram(act_diff)\n",
        "    # axes[i].stairs(counts, bins)\n",
        "    # print(len(np.argwhere(act_diff > 0.3)))\n",
        "\n",
        "    pca = PCA(n_components=3)\n",
        "    transformed = pd.DataFrame(pca.fit_transform(layer_head_wise_activations))\n",
        "    # axes[i,0].scatter(transformed[labels==1][0], transformed[labels==1][1], label='Truthful', c='blue')\n",
        "    # axes[i,0].scatter(transformed[labels==0][0], transformed[labels==0][1], label='Non-truthful', c='yellow')\n",
        "    # axes[i,1].scatter(transformed[labels==1][0], transformed[labels==1][2], label='Truthful', c='blue')\n",
        "    # axes[i,1].scatter(transformed[labels==0][0], transformed[labels==0][2], label='Non-truthful', c='yellow')\n",
        "    # axes[i,2].scatter(transformed[labels==1][1], transformed[labels==1][2], label='Truthful', c='blue')\n",
        "    # axes[i,2].scatter(transformed[labels==0][1], transformed[labels==0][2], label='Non-truthful', c='yellow')\n",
        "    # 3d\n",
        "    axes[i].scatter(transformed[labels==1][0], transformed[labels==1][1], transformed[labels==1][2], label='Truthful', c='blue')\n",
        "    axes[i].scatter(transformed[labels==0][0], transformed[labels==0][1], transformed[labels==0][2], label='Non-truthful', c='yellow')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q8d_ycCO5yT"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 5))\n",
        "for i,(layer,head) in enumerate([(0,0),(11,2)]): # range(32):\n",
        "    layer_head_wise_activations = np.squeeze(head_wise_activations[:,layer,head,:])\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(layer_head_wise_activations)\n",
        "    print(tsne.kl_divergence_)\n",
        "    axes[i].scatter(x=X_tsne[labels==1, 0], y=X_tsne[labels==1, 1], color='blue')\n",
        "    axes[i].scatter(x=X_tsne[labels==0, 0], y=X_tsne[labels==0, 1], color='yellow')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDkNuS8U0ECI"
      },
      "source": [
        "### Feed-forward Probe / Probing multiple tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b77XhSu50Cri"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Non-linearity\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        # Linear function (readout)\n",
        "        # self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function  # LINEAR\n",
        "        out = self.fc1(x)\n",
        "\n",
        "        # # Non-linearity  # NON-LINEAR\n",
        "        # out = self.sigmoid(out)\n",
        "        # # Linear function (readout)  # LINEAR\n",
        "        # out = self.fc2(out)\n",
        "\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_NHcMRoGiQ9"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "num_layers = 32\n",
        "mlp_dims = 11008\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"truthful_qa\", \"generation\", streaming= True)['validation']\n",
        "len_dataset = 817\n",
        "# dataset = load_dataset(\"OamPatel/iti_nq_open_val\", streaming= True)['validation']\n",
        "# len_dataset = 3610\n",
        "actual_labels= []\n",
        "len_labels = 0\n",
        "for val in list(dataset.take(len_dataset)):\n",
        "    actual_labels.append([1 for ans in val['correct_answers']]+[0 for ans in val['incorrect_answers']]) # tqa\n",
        "    # cur_labels = [1 for ans in val['correct_answers'] if ans!='']+[0 for ans in val['incorrect_answers'] if ans!=''] # tqa answer_all\n",
        "    # if len_labels+len(cur_labels)>520:\n",
        "    #     cur_labels = cur_labels[:(520-len_labels)]\n",
        "    #     actual_labels.append(cur_labels)\n",
        "    #     break\n",
        "    # else:\n",
        "    #     actual_labels.append(cur_labels)\n",
        "    # len_labels += len(cur_labels)\n",
        "    # actual_labels.append([1 for ans in val['answer']]+[0]) # nq\n",
        "idxs_to_split_at = np.cumsum([len(x) for x in actual_labels])\n",
        "\n",
        "labels = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_labels_6000.npy\")\n",
        "# labels = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_answer_all_labels_520.npy\")\n",
        "labels = list(labels)\n",
        "separated_labels = []\n",
        "for i in range(len(idxs_to_split_at)):\n",
        "    if i == 0:\n",
        "        separated_labels.append(labels[:idxs_to_split_at[i]])\n",
        "    else:\n",
        "        separated_labels.append(labels[idxs_to_split_at[i-1]:idxs_to_split_at[i]])\n",
        "assert separated_labels == actual_labels\n",
        "\n",
        "# file_ends = [1000,3000,4000,5000,6000] # tqa\n",
        "file_ends = [(a*100)+100 for a in range(int(6000/100))] # tqa mlp_l1 last\n",
        "# file_ends = [(a*20)+20 for a in range(int(500/20)+1)] # tqa answer_all\n",
        "# file_ends = [1000,3000,5000,7000,9000,11000] # nq\n",
        "mlp_wise_activations = []\n",
        "for file_end in file_ends:\n",
        "    # mlp_wise_activations.append(np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_mlp_wise_{file_end}.npy\"))\n",
        "    mlp_wise_activations.append(np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_last_mlp_l1_{file_end}.pkl\",allow_pickle=True)) # mlp l1 last\n",
        "    # acts = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_answer_all_mlp_wise_{file_end}.pkl\",allow_pickle=True) # mlp final\n",
        "    # acts = np.load(f\"/content/gdrive/MyDrive/honest_llama/features/llama_7B_tqa_gen_answer_all_mlp_l1_{file_end}.pkl\",allow_pickle=True) # mlp l1 answer_all\n",
        "    # mlp_wise_activations.append(np.stack([act[:,-1,:] for act in acts], axis=0)) # only last token\n",
        "    # mlp_wise_activations.append(np.stack([act[:,0,:] for act in acts], axis=0)) # only first token\n",
        "    # mlp_wise_activations.append(np.stack([np.mean(act,axis=1) for act in acts], axis=0)) # avg across all tokens\n",
        "    # mlp_wise_activations.append(np.stack([np.max(act,axis=1) for act in acts], axis=0)) # max across all tokens\n",
        "mlp_wise_activations = np.concatenate(mlp_wise_activations, axis=0)\n",
        "assert mlp_wise_activations.shape[1:] == (32, mlp_dims)\n",
        "separated_mlp_wise_activations = np.split(mlp_wise_activations, idxs_to_split_at)\n",
        "if len(separated_mlp_wise_activations[-1])==0:\n",
        "    separated_mlp_wise_activations = separated_mlp_wise_activations[:-1]\n",
        "assert len(separated_labels)==len(separated_mlp_wise_activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tCyvQomMpYS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Individual probes\n",
        "len_dataset = len(separated_mlp_wise_activations)\n",
        "\n",
        "all_accs = {}\n",
        "fold_idxs = np.array_split(np.arange(len_dataset), 2)\n",
        "for i in range(2):\n",
        "    train_idxs = np.concatenate([fold_idxs[j] for j in range(2) if j != i])\n",
        "    train_set_idxs = np.random.choice(train_idxs, size=int(len(train_idxs)*(1-0.2)), replace=False)\n",
        "    val_set_idxs = np.array([x for x in train_idxs if x not in train_set_idxs])\n",
        "\n",
        "    # tot = len(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0))\n",
        "    # print('baseline accuracy:',max(sum(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0))\n",
        "    #                               ,tot-sum(np.concatenate([separated_labels[i] for i in val_set_idxs],axis=0))\n",
        "    #                               )/tot)\n",
        "\n",
        "    all_X_train = np.concatenate([separated_mlp_wise_activations[i] for i in train_set_idxs], axis = 0)\n",
        "    all_X_val = np.concatenate([separated_mlp_wise_activations[i] for i in val_set_idxs], axis = 0)\n",
        "    y_train = np.concatenate([separated_labels[i] for i in train_set_idxs], axis = 0)\n",
        "    y_val = np.concatenate([separated_labels[i] for i in val_set_idxs], axis = 0)\n",
        "    # y_train = np.vstack([np.array([0,1]) if val==1 else (1,0) for val in y_train], dtype='float32')\n",
        "    # y_val = np.vstack([np.array([0,1]) if val==1 else (1,0) for val in y_val], dtype='float32')\n",
        "\n",
        "    all_accs[i] = []\n",
        "    for layer in tqdm(range(num_layers)):\n",
        "    # for layer in [11]:\n",
        "        X_train = all_X_train[:,layer,:] # np.squeeze(np.take(np.squeeze(all_X_train[:,layer,:]), chosen_dims[layer], axis=1)) # all_X_train[:,layer,:]\n",
        "        X_val = all_X_val[:,layer,:] # np.squeeze(np.take(np.squeeze(all_X_val[:,layer,:]), chosen_dims[layer], axis=1)) # all_X_val[:,layer,:]\n",
        "\n",
        "        clf = LogisticRegression(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
        "        y_val_pred = clf.predict(X_val)\n",
        "        # print(accuracy_score(y_val, y_val_pred))\n",
        "        all_accs[i].append(accuracy_score(y_val, y_val_pred))\n",
        "\n",
        "        # ds_train = Dataset.from_dict({\"inputs\": X_train, \"labels\": y_train}).with_format(\"torch\")\n",
        "        # ds_train = DataLoader(ds_train, batch_size=4)\n",
        "        # ds_val = Dataset.from_dict({\"inputs\": X_val, \"labels\": y_val}).with_format(\"torch\")\n",
        "        # ds_val = DataLoader(ds_val, batch_size=4)\n",
        "\n",
        "        # input_dim = 4096 # len(chosen_dims[layer]) # 4096\n",
        "        # hidden_dim = 256\n",
        "        # output_dim = 2\n",
        "\n",
        "        # model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "        # criterion = nn.BCELoss() # nn.CrossEntropyLoss()\n",
        "        # lr = 0.05\n",
        "        # iter_bar = tqdm(ds_train, desc='Train Iter (loss=X.XXX)')\n",
        "\n",
        "        # for epoch in range(10):\n",
        "        #   model.train()\n",
        "        #   optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "        #   for step,batch in enumerate(iter_bar):\n",
        "        #       optimizer.zero_grad()\n",
        "        #       outputs = model(batch['inputs'])\n",
        "        #       loss = criterion(outputs, batch['labels'])\n",
        "        #       iter_bar.set_description('Train Iter (loss=%5.3f)' % loss.item())\n",
        "        #       loss.backward()\n",
        "        #       optimizer.step()\n",
        "        #   lr = lr*0.9\n",
        "        # pred_correct = 0\n",
        "        # with torch.no_grad():\n",
        "        #   model.eval()\n",
        "        #   for step,batch in enumerate(ds_val):\n",
        "        #       outputs = model(batch['inputs'])\n",
        "        #       predicted = torch.argmax(outputs.data, axis=1)\n",
        "        #       actual = torch.argmax(batch['labels'], axis=1)\n",
        "        #       pred_correct += torch.sum(predicted==actual).item()\n",
        "        # print('Validation Acc:',pred_correct/len(X_val))\n",
        "        # all_accs[i].append(pred_correct/len(X_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub9B_EKhMqR9"
      },
      "outputs": [],
      "source": [
        "# Single probe\n",
        "len_dataset = len(separated_mlp_wise_activations)\n",
        "\n",
        "fold_idxs = np.array_split(np.arange(len_dataset), 2)\n",
        "for i in range(2):\n",
        "    train_idxs = np.concatenate([fold_idxs[j] for j in range(2) if j != i])\n",
        "    train_set_idxs = np.random.choice(train_idxs, size=int(len(train_idxs)*(1-0.2)), replace=False)\n",
        "    val_set_idxs = np.array([x for x in train_idxs if x not in train_set_idxs])\n",
        "\n",
        "    all_X_train = np.concatenate([separated_mlp_wise_activations[i] for i in train_set_idxs], axis = 0)\n",
        "    all_X_val = np.concatenate([separated_mlp_wise_activations[i] for i in val_set_idxs], axis = 0)\n",
        "    y_train = np.concatenate([separated_labels[i] for i in train_set_idxs], axis = 0)\n",
        "    y_val = np.concatenate([separated_labels[i] for i in val_set_idxs], axis = 0)\n",
        "    # y_train = np.vstack([np.array([0,1]) if val==1 else (1,0) for val in y_train], dtype='float32')\n",
        "    # y_val = np.vstack([np.array([0,1]) if val==1 else (1,0) for val in y_val], dtype='float32')\n",
        "\n",
        "    X_train = np.reshape(all_X_train,(all_X_train.shape[0],all_X_train.shape[1]*all_X_train.shape[2]))\n",
        "    X_val = np.reshape(all_X_val,(all_X_val.shape[0],all_X_val.shape[1]*all_X_val.shape[2]))\n",
        "\n",
        "    clf = LogisticRegression(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
        "    y_val_pred = clf.predict(X_val)\n",
        "    print(accuracy_score(y_val, y_val_pred))\n",
        "\n",
        "    # ds_train = Dataset.from_dict({\"inputs\": X_train, \"labels\": y_train}).with_format(\"torch\")\n",
        "    # ds_train = DataLoader(ds_train, batch_size=4)\n",
        "    # ds_val = Dataset.from_dict({\"inputs\": X_val, \"labels\": y_val}).with_format(\"torch\")\n",
        "    # ds_val = DataLoader(ds_val, batch_size=4)\n",
        "\n",
        "    # input_dim = X_train.shape[1] # len(chosen_dims[layer]) # 4096\n",
        "    # hidden_dim = 256\n",
        "    # output_dim = 2\n",
        "\n",
        "    # model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "    # criterion = nn.BCELoss() # nn.CrossEntropyLoss()\n",
        "    # lr = 0.05\n",
        "    # iter_bar = tqdm(ds_train, desc='Train Iter (loss=X.XXX)')\n",
        "\n",
        "    # for epoch in range(10):\n",
        "    #   model.train()\n",
        "    #   optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    #   for step,batch in enumerate(iter_bar):\n",
        "    #       optimizer.zero_grad()\n",
        "    #       outputs = model(batch['inputs'])\n",
        "    #       loss = criterion(outputs, batch['labels'])\n",
        "    #       iter_bar.set_description('Train Iter (loss=%5.3f)' % loss.item())\n",
        "    #       loss.backward()\n",
        "    #       optimizer.step()\n",
        "    #   lr = lr*0.9\n",
        "    # pred_correct = 0\n",
        "    # with torch.no_grad():\n",
        "    #   model.eval()\n",
        "    #   for step,batch in enumerate(ds_val):\n",
        "    #       outputs = model(batch['inputs'])\n",
        "    #       predicted = torch.argmax(outputs.data, axis=1)\n",
        "    #       actual = torch.argmax(batch['labels'], axis=1)\n",
        "    #       pred_correct += torch.sum(predicted==actual).item()\n",
        "    # print('Validation Acc:',pred_correct/len(X_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdjIlIGEqrp1"
      },
      "source": [
        "## Analysis - NQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-xct5O6qviR"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "cd validation\n",
        "\n",
        "# python mlp_probe.py llama_7B --dataset_name nq --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "python ah_probe.py llama_7B --dataset_name nq --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe.py llama_7B --dataset_name nq --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python ah_probe.py llama_7B --dataset_name nq --device 0 --num_fold 2 --type_probes single --save_path /content/gdrive/MyDrive/honest_llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJfrtUMV1jw5",
        "outputId": "9418b26f-d88a-45df-f4dd-7f5aee52c80c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP best probe acc:  0.7593873517786561  Layer 13\n",
            "AH best probe acc:  0.751176359872012 Layer: 11.0 Head: 15\n",
            "Best head truth var: 0.02487\n",
            "Best head false var: 0.02237\n",
            "\n",
            "\n",
            "MLP avg probe acc:  0.7306474096555619\n",
            "AH avg probe acc:  0.650301203269104\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_nq_2_ind_mlp_probe_accs.npy')\n",
        "ah_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_nq_2_ind_ah_probe_accs.npy')\n",
        "truth_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_nq_2_ind_ah_probe_bestprobe_trueActsVar.npy')\n",
        "false_var = np.load('/content/gdrive/MyDrive/honest_llama/probes/llama_7B_nq_2_ind_ah_probe_bestprobe_falseActsVar.npy')\n",
        "\n",
        "print('MLP best probe acc: ',np.max(np.mean(mlp_probe_accs, axis=0)), ' Layer', np.argmax(np.mean(mlp_probe_accs, axis=0)))\n",
        "head = np.argmax(np.mean(ah_probe_accs, axis=0))\n",
        "print('AH best probe acc: ',np.max(np.mean(ah_probe_accs, axis=0)), 'Layer:',np.floor(head/32), 'Head:',head%32)\n",
        "print('Best head truth var:',truth_var)\n",
        "print('Best head false var:',false_var)\n",
        "print('\\n')\n",
        "print('MLP avg probe acc: ',np.mean(mlp_probe_accs))\n",
        "print('AH avg probe acc: ',np.mean(ah_probe_accs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tq6m2HZJqPx"
      },
      "source": [
        "## Analysis - MI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eExJ4VdPJryC",
        "outputId": "61b4cffb-5e5e-4bec-9ea8-f86f8ff9641b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "all_prompts = []\n",
        "with open('/content/gdrive/MyDrive/honest_llama/responses/flan_33B_annomi_greedy_responses_500.json', 'r') as read_file:\n",
        "    data = []\n",
        "    for line in read_file:\n",
        "        data.append(json.loads(line))\n",
        "# parrotting = []\n",
        "# for i,row in enumerate(data):\n",
        "#     question = row['prompt']\n",
        "#     answer = row['response1']\n",
        "#     if answer in question:\n",
        "#         parrotting.append(1)\n",
        "#     else:\n",
        "#         parrotting.append(0)\n",
        "# print(sum(parrotting))\n",
        "# np.save('/content/gdrive/MyDrive/honest_llama/responses/flan_33B_annomi_greedy_responses_500_parrotting_labels.npy',parrotting)\n",
        "completion = []\n",
        "for i,row in enumerate(data):\n",
        "    question = row['prompt']\n",
        "    answer = row['response1']\n",
        "    if '<client>' in answer and '<therapist>' in answer:\n",
        "        completion.append(1)\n",
        "    else:\n",
        "        completion.append(0)\n",
        "print(sum(completion))\n",
        "np.save('/content/gdrive/MyDrive/honest_llama/responses/flan_33B_annomi_greedy_responses_500_completion_labels.npy',completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmrMfwwxJvp3",
        "outputId": "9f04a7a7-dfcd-48e0-9df9-4e4f707dc71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/envs/iti/lib/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 116\n",
            "CUDA SETUP: Loading binary /usr/local/envs/iti/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...\n",
            "Running fold 0\n",
            "FOLD 0\n",
            "Running fold 1\n",
            "FOLD 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-23 14:31:40.140484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-23 14:31:40.991702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/envs/iti/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/envs/iti/lib/libcudart.so'), PosixPath('/usr/local/envs/iti/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "\r  0%|          | 0/60 [00:00<?, ?it/s]\r  3%|▎         | 2/60 [00:00<00:03, 17.13it/s]\r  7%|▋         | 4/60 [00:00<00:03, 16.04it/s]\r 10%|█         | 6/60 [00:00<00:03, 15.98it/s]\r 13%|█▎        | 8/60 [00:00<00:03, 15.78it/s]\r 17%|█▋        | 10/60 [00:00<00:03, 15.45it/s]\r 20%|██        | 12/60 [00:00<00:03, 14.53it/s]\r 23%|██▎       | 14/60 [00:00<00:03, 14.67it/s]\r 27%|██▋       | 16/60 [00:01<00:03, 14.46it/s]\r 30%|███       | 18/60 [00:01<00:02, 14.53it/s]\r 33%|███▎      | 20/60 [00:01<00:02, 14.23it/s]\r 37%|███▋      | 22/60 [00:01<00:02, 13.71it/s]\r 40%|████      | 24/60 [00:01<00:03,  9.73it/s]\r 43%|████▎     | 26/60 [00:02<00:03, 10.47it/s]\r 47%|████▋     | 28/60 [00:02<00:02, 10.78it/s]\r 50%|█████     | 30/60 [00:02<00:02, 10.84it/s]\r 53%|█████▎    | 32/60 [00:02<00:02, 10.91it/s]\r 57%|█████▋    | 34/60 [00:02<00:02, 10.59it/s]\r 60%|██████    | 36/60 [00:02<00:02, 10.73it/s]\r 63%|██████▎   | 38/60 [00:03<00:01, 11.07it/s]\r 67%|██████▋   | 40/60 [00:03<00:01, 10.91it/s]\r 70%|███████   | 42/60 [00:03<00:01, 11.45it/s]\r 73%|███████▎  | 44/60 [00:03<00:01, 10.84it/s]\r 77%|███████▋  | 46/60 [00:03<00:01, 10.68it/s]\r 80%|████████  | 48/60 [00:04<00:01,  9.75it/s]\r 83%|████████▎ | 50/60 [00:04<00:01,  9.75it/s]\r 85%|████████▌ | 51/60 [00:04<00:00,  9.73it/s]\r 87%|████████▋ | 52/60 [00:04<00:00,  9.75it/s]\r 88%|████████▊ | 53/60 [00:04<00:00,  9.14it/s]\r 90%|█████████ | 54/60 [00:04<00:00,  8.33it/s]\r 92%|█████████▏| 55/60 [00:04<00:00,  7.69it/s]\r 93%|█████████▎| 56/60 [00:05<00:00,  6.62it/s]\r 95%|█████████▌| 57/60 [00:05<00:00,  6.21it/s]\r 97%|█████████▋| 58/60 [00:05<00:00,  5.80it/s]\r 98%|█████████▊| 59/60 [00:05<00:00,  4.86it/s]\r100%|██████████| 60/60 [00:06<00:00,  2.67it/s]\r100%|██████████| 60/60 [00:06<00:00,  9.08it/s]\n",
            "\r  0%|          | 0/60 [00:00<?, ?it/s]\r  3%|▎         | 2/60 [00:00<00:04, 14.36it/s]\r  7%|▋         | 4/60 [00:00<00:04, 13.32it/s]\r 10%|█         | 6/60 [00:00<00:04, 12.55it/s]\r 13%|█▎        | 8/60 [00:00<00:06,  7.57it/s]\r 17%|█▋        | 10/60 [00:01<00:06,  8.29it/s]\r 18%|█▊        | 11/60 [00:01<00:05,  8.51it/s]\r 22%|██▏       | 13/60 [00:01<00:05,  9.12it/s]\r 25%|██▌       | 15/60 [00:01<00:04,  9.78it/s]\r 28%|██▊       | 17/60 [00:01<00:04, 10.43it/s]\r 32%|███▏      | 19/60 [00:01<00:03, 10.93it/s]\r 35%|███▌      | 21/60 [00:02<00:03, 11.03it/s]\r 38%|███▊      | 23/60 [00:02<00:03, 11.23it/s]\r 42%|████▏     | 25/60 [00:02<00:03, 11.07it/s]\r 45%|████▌     | 27/60 [00:02<00:03, 10.71it/s]\r 48%|████▊     | 29/60 [00:02<00:02, 10.39it/s]\r 52%|█████▏    | 31/60 [00:03<00:02,  9.96it/s]\r 55%|█████▌    | 33/60 [00:03<00:02,  9.95it/s]\r 58%|█████▊    | 35/60 [00:03<00:02,  9.54it/s]\r 60%|██████    | 36/60 [00:03<00:02,  9.46it/s]\r 62%|██████▏   | 37/60 [00:03<00:02,  9.37it/s]\r 63%|██████▎   | 38/60 [00:03<00:02,  9.45it/s]\r 65%|██████▌   | 39/60 [00:03<00:02,  9.48it/s]\r 67%|██████▋   | 40/60 [00:04<00:02,  9.55it/s]\r 68%|██████▊   | 41/60 [00:04<00:01,  9.61it/s]\r 72%|███████▏  | 43/60 [00:04<00:01,  9.67it/s]\r 73%|███████▎  | 44/60 [00:04<00:01,  9.42it/s]\r 75%|███████▌  | 45/60 [00:04<00:02,  6.53it/s]\r 77%|███████▋  | 46/60 [00:04<00:01,  7.15it/s]\r 78%|███████▊  | 47/60 [00:04<00:01,  7.04it/s]\r 80%|████████  | 48/60 [00:05<00:01,  7.35it/s]\r 82%|████████▏ | 49/60 [00:05<00:01,  7.74it/s]\r 83%|████████▎ | 50/60 [00:05<00:01,  8.05it/s]\r 85%|████████▌ | 51/60 [00:05<00:01,  8.29it/s]\r 87%|████████▋ | 52/60 [00:05<00:00,  8.24it/s]\r 88%|████████▊ | 53/60 [00:05<00:00,  8.04it/s]\r 90%|█████████ | 54/60 [00:05<00:00,  7.47it/s]\r 92%|█████████▏| 55/60 [00:06<00:00,  7.08it/s]\r 93%|█████████▎| 56/60 [00:06<00:00,  6.29it/s]\r 95%|█████████▌| 57/60 [00:06<00:00,  6.15it/s]\r 97%|█████████▋| 58/60 [00:06<00:00,  6.02it/s]\r 98%|█████████▊| 59/60 [00:06<00:00,  5.49it/s]\r100%|██████████| 60/60 [00:07<00:00,  3.10it/s]\r100%|██████████| 60/60 [00:07<00:00,  8.08it/s]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate iti\n",
        "cd validation\n",
        "\n",
        "# python mlp_probe_mi.py flan_33B --dataset_name counselling --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe_mi.py flan_33B --dataset_name counselling --device 0 --num_fold 2 --type_probes vote_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe_mi.py flan_33B --dataset_name counselling --device 0 --num_fold 2 --type_probes lr_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "\n",
        "# python mlp_probe_mi.py flan_33B --dataset_name counselling --error_type completion --device 0 --num_fold 2 --save_path /content/gdrive/MyDrive/honest_llama\n",
        "# python mlp_probe_mi.py flan_33B --dataset_name counselling --error_type completion --device 0 --num_fold 2 --type_probes vote_on_ind --save_path /content/gdrive/MyDrive/honest_llama\n",
        "python mlp_probe_mi.py flan_33B --dataset_name counselling --error_type completion --device 0 --num_fold 2 --type_probes lr_on_ind --save_path /content/gdrive/MyDrive/honest_llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFVw3RTiPp91",
        "outputId": "a839ca9e-5e0e-4126-b65b-8e9ac0b15310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP best probe acc:  0.97  Layer 7\n",
            "\n",
            "\n",
            "MLP avg probe acc:  0.9448333333333333\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_ind_mlp_probe_accs.npy')\n",
        "\n",
        "print('MLP best probe acc: ',np.max(np.mean(mlp_probe_accs, axis=0)), ' Layer', np.argmax(np.mean(mlp_probe_accs, axis=0)))\n",
        "print('\\n')\n",
        "print('MLP avg probe acc: ',np.mean(mlp_probe_accs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjC5OsGuRjUV"
      },
      "source": [
        "### Vote\\LR on ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsxMfKKER_c8",
        "outputId": "320f6e69-542e-48ef-8780-dd762968adef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP probe acc (vote over individual):  0.89\n",
            "MLP probe acc (additional layer over individual):  0.9299999999999999\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_vote_on_ind_mlp_probe_accs.npy')\n",
        "print('MLP probe acc (vote over individual): ',np.mean(mlp_probe_accs))\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_lr_on_ind_mlp_probe_accs.npy')\n",
        "print('MLP probe acc (additional layer over individual): ',np.mean(mlp_probe_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "bwc4V5y2SZ6K",
        "outputId": "b85c7cd9-bcc5-49e0-890b-1d9336f29dbb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_ind_mlp_probe_accs.npy')\n",
        "\n",
        "\n",
        "sns.heatmap(mlp_probe_accs, linewidth=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArrYW5-PQS0I"
      },
      "source": [
        "### Probe Coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4KsPmWSQUTn",
        "outputId": "8e81c21d-43d6-4fb1-8750-ebd52ff466bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07366700321012544\n",
            "-0.08430466109537721\n",
            "0.1 0.3518796992481203\n",
            "0.2 0.43350864012021034\n",
            "0.3 0.5\n",
            "0.4 0.5473328324567994\n",
            "0.5 0.6066706730769231\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "mlp_probe_coef = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_ind_mlp_probe_coef.npy')\n",
        "\n",
        "mlp_probe_coef.shape\n",
        "mlp_probe_coef = mlp_probe_coef.reshape(2,60,6656)\n",
        "var = np.empty(mlp_probe_coef.shape[:2])\n",
        "for fold in [0,1]:\n",
        "    for layer in range(60):\n",
        "        var[fold,layer] = np.var(np.absolute(mlp_probe_coef[fold,layer,:]))\n",
        "\n",
        "# sns.heatmap(var, linewidth=0.5)\n",
        "\n",
        "mlp_probe_accs = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_ind_mlp_probe_accs.npy')\n",
        "print(np.corrcoef(mlp_probe_accs[0],var[0])[0,1])\n",
        "print(np.corrcoef(mlp_probe_accs[1],var[1])[0,1])\n",
        "\n",
        "for top_perc in [0.1,0.2,0.3,0.4,0.5]:\n",
        "    topx = int(mlp_probe_coef.shape[2]*top_perc)\n",
        "    val0_top = np.argsort(np.absolute(mlp_probe_coef[0][7]))[-topx:]\n",
        "    val1_top = np.argsort(np.absolute(mlp_probe_coef[1][7]))[-topx:]\n",
        "    print(top_perc,np.sum([1 for idx in val0_top if idx in val1_top])/topx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF8G87-cTyAB",
        "outputId": "39b5af71-2318-442c-b936-fe8d61fa74bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12 14\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "mlp_probe_pred = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_vote_on_ind_mlp_probe_pred.npy',allow_pickle=True)\n",
        "y_true = np.load('/content/gdrive/MyDrive/honest_llama/probes/flan_33B_counselling_completion_2_vote_on_ind_mlp_probe_true.npy',allow_pickle=True)\n",
        "\n",
        "print(sum(y_true[0]), sum(y_true[1]))\n",
        "\n",
        "ind_hard_samples = {}\n",
        "for fold in [0,1]:\n",
        "    ind_hard_samples[fold] = []\n",
        "    for i,sample_pred in enumerate(mlp_probe_pred[fold]):\n",
        "        # print(np.sum(np.argmax(sample_pred,axis=1)),y_true[fold][i])\n",
        "        if any(np.argmax(sample_pred,axis=1)==y_true[fold][i])==False:\n",
        "            ind_hard_samples[fold].append(i)\n",
        "print(len(ind_hard_samples[0]))\n",
        "print(len(ind_hard_samples[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oEHGOkzydML",
        "outputId": "a9c5df94-895d-4cb9-db24-e327831bce4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82 200 20 50\n",
            "baseline accuracy: 0.6\n",
            "87 200 16 50\n",
            "baseline accuracy: 0.68\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "labels = np.load(f\"/content/gdrive/MyDrive/honest_llama/responses/flan_33B_annomi_greedy_responses_500_parrotting_labels.npy\")\n",
        "fold_idxs = np.array_split(np.arange(500), 2)\n",
        "for i in range(2):\n",
        "    train_idxs = np.concatenate([fold_idxs[j] for j in range(2) if j != i])\n",
        "    train_set_idxs = np.random.choice(train_idxs, size=int(len(train_idxs)*(1-0.2)), replace=False)\n",
        "    val_set_idxs = np.array([x for x in train_idxs if x not in train_set_idxs])\n",
        "    print(sum([labels[i] for i in train_set_idxs]),len(train_set_idxs),sum([labels[i] for i in val_set_idxs]),len(val_set_idxs))\n",
        "    print('baseline accuracy:',max(sum([labels[i] for i in val_set_idxs])\n",
        "                                  ,len(val_set_idxs)-sum([labels[i] for i in val_set_idxs])\n",
        "                                  )/len(val_set_idxs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uboT0Fq9_e-5"
      },
      "source": [
        "### Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeNHzADN_iEc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuJfXF740yOa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ubQLBR5DLie_",
        "D5tkuqifLY5K",
        "3YWhJwtPC2p1",
        "nMAdQnKQC403",
        "5xTttmMuz08e",
        "ThKgGDNdO4G-",
        "oj8P8455Vl4Q",
        "zDkNuS8U0ECI",
        "qdjIlIGEqrp1",
        "-tq6m2HZJqPx",
        "LjC5OsGuRjUV",
        "ArrYW5-PQS0I",
        "uboT0Fq9_e-5"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}